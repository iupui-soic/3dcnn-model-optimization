{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b935ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch==1.8.1 torchvision==0.9.1\n",
    "#!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html #(this works, the previous installation did not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e9e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from resnet import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03112d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training Model...\n",
      "Epoch: -1 Eval Loss: 2.325 Eval Acc: 0.098\n",
      "Epoch: 000 Train Loss: 2.063 Train Acc: 0.309 Eval Loss: 1.740 Eval Acc: 0.422\n",
      "Epoch: 001 Train Loss: 1.499 Train Acc: 0.453 Eval Loss: 1.337 Eval Acc: 0.511\n",
      "Epoch: 002 Train Loss: 1.299 Train Acc: 0.532 Eval Loss: 1.202 Eval Acc: 0.576\n",
      "Epoch: 003 Train Loss: 1.160 Train Acc: 0.585 Eval Loss: 1.131 Eval Acc: 0.600\n",
      "Epoch: 004 Train Loss: 1.050 Train Acc: 0.627 Eval Loss: 0.984 Eval Acc: 0.655\n",
      "Epoch: 005 Train Loss: 0.969 Train Acc: 0.658 Eval Loss: 0.952 Eval Acc: 0.674\n",
      "Epoch: 006 Train Loss: 0.898 Train Acc: 0.685 Eval Loss: 0.910 Eval Acc: 0.686\n",
      "Epoch: 007 Train Loss: 0.853 Train Acc: 0.699 Eval Loss: 0.803 Eval Acc: 0.724\n",
      "Epoch: 008 Train Loss: 0.801 Train Acc: 0.721 Eval Loss: 0.788 Eval Acc: 0.724\n",
      "Epoch: 009 Train Loss: 0.766 Train Acc: 0.732 Eval Loss: 0.788 Eval Acc: 0.732\n",
      "Epoch: 010 Train Loss: 0.735 Train Acc: 0.746 Eval Loss: 0.773 Eval Acc: 0.734\n",
      "Epoch: 011 Train Loss: 0.703 Train Acc: 0.757 Eval Loss: 0.774 Eval Acc: 0.739\n",
      "Epoch: 012 Train Loss: 0.686 Train Acc: 0.764 Eval Loss: 0.701 Eval Acc: 0.762\n",
      "Epoch: 013 Train Loss: 0.662 Train Acc: 0.771 Eval Loss: 0.665 Eval Acc: 0.774\n",
      "Epoch: 014 Train Loss: 0.640 Train Acc: 0.777 Eval Loss: 0.646 Eval Acc: 0.778\n",
      "Epoch: 015 Train Loss: 0.620 Train Acc: 0.785 Eval Loss: 0.624 Eval Acc: 0.786\n",
      "Epoch: 016 Train Loss: 0.613 Train Acc: 0.785 Eval Loss: 0.635 Eval Acc: 0.782\n",
      "Epoch: 017 Train Loss: 0.593 Train Acc: 0.793 Eval Loss: 0.644 Eval Acc: 0.779\n",
      "Epoch: 018 Train Loss: 0.581 Train Acc: 0.797 Eval Loss: 0.650 Eval Acc: 0.781\n",
      "Epoch: 019 Train Loss: 0.565 Train Acc: 0.804 Eval Loss: 0.645 Eval Acc: 0.781\n",
      "Epoch: 020 Train Loss: 0.557 Train Acc: 0.806 Eval Loss: 0.637 Eval Acc: 0.786\n",
      "Epoch: 021 Train Loss: 0.552 Train Acc: 0.807 Eval Loss: 0.639 Eval Acc: 0.787\n",
      "Epoch: 022 Train Loss: 0.538 Train Acc: 0.815 Eval Loss: 0.585 Eval Acc: 0.802\n",
      "Epoch: 023 Train Loss: 0.531 Train Acc: 0.817 Eval Loss: 0.656 Eval Acc: 0.779\n",
      "Epoch: 024 Train Loss: 0.524 Train Acc: 0.819 Eval Loss: 0.627 Eval Acc: 0.786\n",
      "Epoch: 025 Train Loss: 0.516 Train Acc: 0.821 Eval Loss: 0.608 Eval Acc: 0.796\n",
      "Epoch: 026 Train Loss: 0.506 Train Acc: 0.825 Eval Loss: 0.596 Eval Acc: 0.794\n",
      "Epoch: 027 Train Loss: 0.494 Train Acc: 0.829 Eval Loss: 0.608 Eval Acc: 0.794\n",
      "Epoch: 028 Train Loss: 0.493 Train Acc: 0.830 Eval Loss: 0.612 Eval Acc: 0.796\n",
      "Epoch: 029 Train Loss: 0.484 Train Acc: 0.831 Eval Loss: 0.617 Eval Acc: 0.794\n",
      "Epoch: 030 Train Loss: 0.477 Train Acc: 0.835 Eval Loss: 0.595 Eval Acc: 0.800\n",
      "Epoch: 031 Train Loss: 0.474 Train Acc: 0.836 Eval Loss: 0.598 Eval Acc: 0.804\n",
      "Epoch: 032 Train Loss: 0.469 Train Acc: 0.836 Eval Loss: 0.576 Eval Acc: 0.804\n",
      "Epoch: 033 Train Loss: 0.458 Train Acc: 0.841 Eval Loss: 0.585 Eval Acc: 0.804\n",
      "Epoch: 034 Train Loss: 0.460 Train Acc: 0.841 Eval Loss: 0.571 Eval Acc: 0.812\n",
      "Epoch: 035 Train Loss: 0.455 Train Acc: 0.842 Eval Loss: 0.615 Eval Acc: 0.802\n",
      "Epoch: 036 Train Loss: 0.451 Train Acc: 0.843 Eval Loss: 0.546 Eval Acc: 0.819\n",
      "Epoch: 037 Train Loss: 0.441 Train Acc: 0.846 Eval Loss: 0.559 Eval Acc: 0.812\n",
      "Epoch: 038 Train Loss: 0.441 Train Acc: 0.845 Eval Loss: 0.554 Eval Acc: 0.818\n",
      "Epoch: 039 Train Loss: 0.440 Train Acc: 0.846 Eval Loss: 0.584 Eval Acc: 0.811\n",
      "Epoch: 040 Train Loss: 0.435 Train Acc: 0.847 Eval Loss: 0.632 Eval Acc: 0.800\n",
      "Epoch: 041 Train Loss: 0.435 Train Acc: 0.848 Eval Loss: 0.551 Eval Acc: 0.820\n",
      "Epoch: 042 Train Loss: 0.427 Train Acc: 0.850 Eval Loss: 0.565 Eval Acc: 0.814\n",
      "Epoch: 043 Train Loss: 0.424 Train Acc: 0.852 Eval Loss: 0.587 Eval Acc: 0.807\n",
      "Epoch: 044 Train Loss: 0.419 Train Acc: 0.854 Eval Loss: 0.570 Eval Acc: 0.813\n",
      "Epoch: 045 Train Loss: 0.426 Train Acc: 0.850 Eval Loss: 0.597 Eval Acc: 0.803\n",
      "Epoch: 046 Train Loss: 0.413 Train Acc: 0.856 Eval Loss: 0.584 Eval Acc: 0.812\n",
      "Epoch: 047 Train Loss: 0.410 Train Acc: 0.857 Eval Loss: 0.556 Eval Acc: 0.814\n",
      "Epoch: 048 Train Loss: 0.404 Train Acc: 0.858 Eval Loss: 0.569 Eval Acc: 0.815\n",
      "Epoch: 049 Train Loss: 0.403 Train Acc: 0.860 Eval Loss: 0.553 Eval Acc: 0.820\n",
      "Epoch: 050 Train Loss: 0.405 Train Acc: 0.859 Eval Loss: 0.568 Eval Acc: 0.817\n",
      "Epoch: 051 Train Loss: 0.399 Train Acc: 0.861 Eval Loss: 0.539 Eval Acc: 0.826\n",
      "Epoch: 052 Train Loss: 0.393 Train Acc: 0.864 Eval Loss: 0.562 Eval Acc: 0.819\n",
      "Epoch: 053 Train Loss: 0.399 Train Acc: 0.860 Eval Loss: 0.572 Eval Acc: 0.814\n",
      "Epoch: 054 Train Loss: 0.393 Train Acc: 0.862 Eval Loss: 0.579 Eval Acc: 0.813\n",
      "Epoch: 055 Train Loss: 0.392 Train Acc: 0.863 Eval Loss: 0.536 Eval Acc: 0.825\n",
      "Epoch: 056 Train Loss: 0.385 Train Acc: 0.865 Eval Loss: 0.538 Eval Acc: 0.825\n",
      "Epoch: 057 Train Loss: 0.388 Train Acc: 0.865 Eval Loss: 0.580 Eval Acc: 0.817\n",
      "Epoch: 058 Train Loss: 0.387 Train Acc: 0.865 Eval Loss: 0.579 Eval Acc: 0.816\n",
      "Epoch: 059 Train Loss: 0.385 Train Acc: 0.865 Eval Loss: 0.591 Eval Acc: 0.813\n",
      "Epoch: 060 Train Loss: 0.379 Train Acc: 0.868 Eval Loss: 0.572 Eval Acc: 0.821\n",
      "Epoch: 061 Train Loss: 0.378 Train Acc: 0.868 Eval Loss: 0.540 Eval Acc: 0.829\n",
      "Epoch: 062 Train Loss: 0.378 Train Acc: 0.867 Eval Loss: 0.556 Eval Acc: 0.819\n",
      "Epoch: 063 Train Loss: 0.371 Train Acc: 0.871 Eval Loss: 0.562 Eval Acc: 0.819\n",
      "Epoch: 064 Train Loss: 0.375 Train Acc: 0.870 Eval Loss: 0.544 Eval Acc: 0.824\n",
      "Epoch: 065 Train Loss: 0.375 Train Acc: 0.868 Eval Loss: 0.642 Eval Acc: 0.795\n",
      "Epoch: 066 Train Loss: 0.370 Train Acc: 0.872 Eval Loss: 0.535 Eval Acc: 0.826\n",
      "Epoch: 067 Train Loss: 0.370 Train Acc: 0.871 Eval Loss: 0.552 Eval Acc: 0.821\n",
      "Epoch: 068 Train Loss: 0.364 Train Acc: 0.872 Eval Loss: 0.568 Eval Acc: 0.815\n",
      "Epoch: 069 Train Loss: 0.361 Train Acc: 0.874 Eval Loss: 0.520 Eval Acc: 0.832\n",
      "Epoch: 070 Train Loss: 0.359 Train Acc: 0.873 Eval Loss: 0.565 Eval Acc: 0.821\n",
      "Epoch: 071 Train Loss: 0.363 Train Acc: 0.873 Eval Loss: 0.534 Eval Acc: 0.826\n",
      "Epoch: 072 Train Loss: 0.362 Train Acc: 0.875 Eval Loss: 0.571 Eval Acc: 0.820\n",
      "Epoch: 073 Train Loss: 0.366 Train Acc: 0.871 Eval Loss: 0.553 Eval Acc: 0.824\n",
      "Epoch: 074 Train Loss: 0.354 Train Acc: 0.875 Eval Loss: 0.548 Eval Acc: 0.821\n",
      "Epoch: 075 Train Loss: 0.360 Train Acc: 0.876 Eval Loss: 0.530 Eval Acc: 0.832\n",
      "Epoch: 076 Train Loss: 0.353 Train Acc: 0.874 Eval Loss: 0.548 Eval Acc: 0.824\n",
      "Epoch: 077 Train Loss: 0.348 Train Acc: 0.878 Eval Loss: 0.544 Eval Acc: 0.821\n",
      "Epoch: 078 Train Loss: 0.357 Train Acc: 0.874 Eval Loss: 0.516 Eval Acc: 0.836\n",
      "Epoch: 079 Train Loss: 0.348 Train Acc: 0.878 Eval Loss: 0.522 Eval Acc: 0.832\n",
      "Epoch: 080 Train Loss: 0.345 Train Acc: 0.879 Eval Loss: 0.534 Eval Acc: 0.833\n",
      "Epoch: 081 Train Loss: 0.344 Train Acc: 0.879 Eval Loss: 0.524 Eval Acc: 0.830\n",
      "Epoch: 082 Train Loss: 0.350 Train Acc: 0.878 Eval Loss: 0.520 Eval Acc: 0.833\n",
      "Epoch: 083 Train Loss: 0.347 Train Acc: 0.878 Eval Loss: 0.559 Eval Acc: 0.820\n",
      "Epoch: 084 Train Loss: 0.350 Train Acc: 0.879 Eval Loss: 0.557 Eval Acc: 0.823\n",
      "Epoch: 085 Train Loss: 0.345 Train Acc: 0.880 Eval Loss: 0.534 Eval Acc: 0.827\n",
      "Epoch: 086 Train Loss: 0.341 Train Acc: 0.881 Eval Loss: 0.577 Eval Acc: 0.818\n",
      "Epoch: 087 Train Loss: 0.342 Train Acc: 0.881 Eval Loss: 0.537 Eval Acc: 0.829\n",
      "Epoch: 088 Train Loss: 0.341 Train Acc: 0.882 Eval Loss: 0.566 Eval Acc: 0.820\n",
      "Epoch: 089 Train Loss: 0.339 Train Acc: 0.881 Eval Loss: 0.533 Eval Acc: 0.831\n",
      "Epoch: 090 Train Loss: 0.339 Train Acc: 0.881 Eval Loss: 0.515 Eval Acc: 0.838\n",
      "Epoch: 091 Train Loss: 0.333 Train Acc: 0.884 Eval Loss: 0.606 Eval Acc: 0.811\n",
      "Epoch: 092 Train Loss: 0.340 Train Acc: 0.883 Eval Loss: 0.653 Eval Acc: 0.803\n",
      "Epoch: 093 Train Loss: 0.344 Train Acc: 0.880 Eval Loss: 0.567 Eval Acc: 0.827\n",
      "Epoch: 094 Train Loss: 0.331 Train Acc: 0.884 Eval Loss: 0.557 Eval Acc: 0.827\n",
      "Epoch: 095 Train Loss: 0.333 Train Acc: 0.884 Eval Loss: 0.526 Eval Acc: 0.833\n",
      "Epoch: 096 Train Loss: 0.330 Train Acc: 0.884 Eval Loss: 0.566 Eval Acc: 0.821\n",
      "Epoch: 097 Train Loss: 0.334 Train Acc: 0.884 Eval Loss: 0.583 Eval Acc: 0.814\n",
      "Epoch: 098 Train Loss: 0.333 Train Acc: 0.885 Eval Loss: 0.537 Eval Acc: 0.830\n",
      "Epoch: 099 Train Loss: 0.332 Train Acc: 0.883 Eval Loss: 0.550 Eval Acc: 0.831\n",
      "Epoch: 100 Train Loss: 0.222 Train Acc: 0.923 Eval Loss: 0.442 Eval Acc: 0.867\n",
      "Epoch: 101 Train Loss: 0.174 Train Acc: 0.938 Eval Loss: 0.441 Eval Acc: 0.871\n",
      "Epoch: 102 Train Loss: 0.165 Train Acc: 0.944 Eval Loss: 0.449 Eval Acc: 0.871\n",
      "Epoch: 103 Train Loss: 0.150 Train Acc: 0.948 Eval Loss: 0.446 Eval Acc: 0.874\n",
      "Epoch: 104 Train Loss: 0.141 Train Acc: 0.951 Eval Loss: 0.455 Eval Acc: 0.872\n",
      "Epoch: 110 Train Loss: 0.110 Train Acc: 0.961 Eval Loss: 0.486 Eval Acc: 0.873\n",
      "Epoch: 111 Train Loss: 0.107 Train Acc: 0.962 Eval Loss: 0.490 Eval Acc: 0.872\n",
      "Epoch: 112 Train Loss: 0.104 Train Acc: 0.963 Eval Loss: 0.493 Eval Acc: 0.876\n",
      "Epoch: 113 Train Loss: 0.104 Train Acc: 0.963 Eval Loss: 0.486 Eval Acc: 0.873\n",
      "Epoch: 114 Train Loss: 0.100 Train Acc: 0.965 Eval Loss: 0.490 Eval Acc: 0.873\n",
      "Epoch: 115 Train Loss: 0.095 Train Acc: 0.966 Eval Loss: 0.496 Eval Acc: 0.874\n",
      "Epoch: 116 Train Loss: 0.094 Train Acc: 0.965 Eval Loss: 0.505 Eval Acc: 0.873\n",
      "Epoch: 117 Train Loss: 0.092 Train Acc: 0.968 Eval Loss: 0.518 Eval Acc: 0.872\n",
      "Epoch: 118 Train Loss: 0.089 Train Acc: 0.968 Eval Loss: 0.521 Eval Acc: 0.873\n",
      "Epoch: 119 Train Loss: 0.086 Train Acc: 0.969 Eval Loss: 0.520 Eval Acc: 0.873\n",
      "Epoch: 120 Train Loss: 0.085 Train Acc: 0.970 Eval Loss: 0.517 Eval Acc: 0.874\n",
      "Epoch: 121 Train Loss: 0.079 Train Acc: 0.972 Eval Loss: 0.530 Eval Acc: 0.875\n",
      "Epoch: 122 Train Loss: 0.082 Train Acc: 0.972 Eval Loss: 0.539 Eval Acc: 0.873\n",
      "Epoch: 123 Train Loss: 0.079 Train Acc: 0.972 Eval Loss: 0.541 Eval Acc: 0.870\n",
      "Epoch: 124 Train Loss: 0.076 Train Acc: 0.973 Eval Loss: 0.536 Eval Acc: 0.872\n",
      "Epoch: 125 Train Loss: 0.076 Train Acc: 0.973 Eval Loss: 0.534 Eval Acc: 0.871\n",
      "Epoch: 126 Train Loss: 0.073 Train Acc: 0.974 Eval Loss: 0.548 Eval Acc: 0.873\n",
      "Epoch: 127 Train Loss: 0.072 Train Acc: 0.975 Eval Loss: 0.554 Eval Acc: 0.872\n",
      "Epoch: 128 Train Loss: 0.070 Train Acc: 0.975 Eval Loss: 0.561 Eval Acc: 0.871\n",
      "Epoch: 129 Train Loss: 0.068 Train Acc: 0.976 Eval Loss: 0.551 Eval Acc: 0.871\n",
      "Epoch: 130 Train Loss: 0.065 Train Acc: 0.976 Eval Loss: 0.566 Eval Acc: 0.871\n",
      "Epoch: 131 Train Loss: 0.071 Train Acc: 0.975 Eval Loss: 0.548 Eval Acc: 0.873\n",
      "Epoch: 132 Train Loss: 0.065 Train Acc: 0.976 Eval Loss: 0.569 Eval Acc: 0.870\n",
      "Epoch: 133 Train Loss: 0.067 Train Acc: 0.976 Eval Loss: 0.567 Eval Acc: 0.869\n",
      "Epoch: 134 Train Loss: 0.063 Train Acc: 0.978 Eval Loss: 0.561 Eval Acc: 0.871\n",
      "Epoch: 135 Train Loss: 0.062 Train Acc: 0.978 Eval Loss: 0.575 Eval Acc: 0.871\n",
      "Epoch: 136 Train Loss: 0.060 Train Acc: 0.979 Eval Loss: 0.578 Eval Acc: 0.871\n",
      "Epoch: 137 Train Loss: 0.060 Train Acc: 0.979 Eval Loss: 0.578 Eval Acc: 0.870\n",
      "Epoch: 138 Train Loss: 0.057 Train Acc: 0.980 Eval Loss: 0.585 Eval Acc: 0.870\n",
      "Epoch: 139 Train Loss: 0.058 Train Acc: 0.979 Eval Loss: 0.590 Eval Acc: 0.873\n",
      "Epoch: 140 Train Loss: 0.056 Train Acc: 0.981 Eval Loss: 0.589 Eval Acc: 0.872\n",
      "Epoch: 141 Train Loss: 0.056 Train Acc: 0.980 Eval Loss: 0.592 Eval Acc: 0.873\n",
      "Epoch: 142 Train Loss: 0.052 Train Acc: 0.981 Eval Loss: 0.596 Eval Acc: 0.871\n",
      "Epoch: 143 Train Loss: 0.056 Train Acc: 0.980 Eval Loss: 0.601 Eval Acc: 0.870\n",
      "Epoch: 144 Train Loss: 0.056 Train Acc: 0.980 Eval Loss: 0.588 Eval Acc: 0.868\n",
      "Epoch: 145 Train Loss: 0.054 Train Acc: 0.981 Eval Loss: 0.588 Eval Acc: 0.873\n",
      "Epoch: 146 Train Loss: 0.053 Train Acc: 0.982 Eval Loss: 0.599 Eval Acc: 0.870\n",
      "Epoch: 147 Train Loss: 0.050 Train Acc: 0.983 Eval Loss: 0.610 Eval Acc: 0.869\n",
      "Epoch: 148 Train Loss: 0.051 Train Acc: 0.982 Eval Loss: 0.610 Eval Acc: 0.870\n",
      "Epoch: 149 Train Loss: 0.052 Train Acc: 0.982 Eval Loss: 0.616 Eval Acc: 0.868\n",
      "Epoch: 150 Train Loss: 0.045 Train Acc: 0.985 Eval Loss: 0.582 Eval Acc: 0.873\n",
      "Epoch: 151 Train Loss: 0.040 Train Acc: 0.986 Eval Loss: 0.584 Eval Acc: 0.876\n",
      "Epoch: 152 Train Loss: 0.036 Train Acc: 0.988 Eval Loss: 0.584 Eval Acc: 0.874\n",
      "Epoch: 153 Train Loss: 0.036 Train Acc: 0.987 Eval Loss: 0.584 Eval Acc: 0.876\n",
      "Epoch: 154 Train Loss: 0.033 Train Acc: 0.989 Eval Loss: 0.589 Eval Acc: 0.875\n",
      "Epoch: 155 Train Loss: 0.033 Train Acc: 0.989 Eval Loss: 0.589 Eval Acc: 0.874\n",
      "Epoch: 156 Train Loss: 0.034 Train Acc: 0.989 Eval Loss: 0.591 Eval Acc: 0.876\n",
      "Epoch: 157 Train Loss: 0.032 Train Acc: 0.989 Eval Loss: 0.586 Eval Acc: 0.877\n",
      "Epoch: 158 Train Loss: 0.029 Train Acc: 0.990 Eval Loss: 0.590 Eval Acc: 0.877\n",
      "Epoch: 159 Train Loss: 0.032 Train Acc: 0.989 Eval Loss: 0.590 Eval Acc: 0.876\n",
      "Epoch: 160 Train Loss: 0.030 Train Acc: 0.990 Eval Loss: 0.593 Eval Acc: 0.877\n",
      "Epoch: 161 Train Loss: 0.030 Train Acc: 0.990 Eval Loss: 0.593 Eval Acc: 0.878\n",
      "Epoch: 162 Train Loss: 0.029 Train Acc: 0.990 Eval Loss: 0.595 Eval Acc: 0.877\n",
      "Epoch: 163 Train Loss: 0.029 Train Acc: 0.991 Eval Loss: 0.595 Eval Acc: 0.878\n",
      "Epoch: 164 Train Loss: 0.029 Train Acc: 0.990 Eval Loss: 0.599 Eval Acc: 0.878\n",
      "Epoch: 165 Train Loss: 0.027 Train Acc: 0.991 Eval Loss: 0.602 Eval Acc: 0.879\n",
      "Epoch: 166 Train Loss: 0.027 Train Acc: 0.991 Eval Loss: 0.601 Eval Acc: 0.879\n",
      "Epoch: 167 Train Loss: 0.028 Train Acc: 0.991 Eval Loss: 0.605 Eval Acc: 0.878\n",
      "Epoch: 168 Train Loss: 0.028 Train Acc: 0.991 Eval Loss: 0.603 Eval Acc: 0.879\n",
      "Epoch: 169 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.608 Eval Acc: 0.878\n",
      "Epoch: 170 Train Loss: 0.027 Train Acc: 0.991 Eval Loss: 0.610 Eval Acc: 0.878\n",
      "Epoch: 171 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.606 Eval Acc: 0.879\n",
      "Epoch: 172 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.609 Eval Acc: 0.878\n",
      "Epoch: 173 Train Loss: 0.025 Train Acc: 0.992 Eval Loss: 0.613 Eval Acc: 0.877\n",
      "Epoch: 174 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.615 Eval Acc: 0.877\n",
      "Epoch: 175 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.613 Eval Acc: 0.879\n",
      "Epoch: 176 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.616 Eval Acc: 0.878\n",
      "Epoch: 177 Train Loss: 0.027 Train Acc: 0.991 Eval Loss: 0.619 Eval Acc: 0.877\n",
      "Epoch: 178 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.620 Eval Acc: 0.877\n",
      "Epoch: 179 Train Loss: 0.025 Train Acc: 0.992 Eval Loss: 0.620 Eval Acc: 0.878\n",
      "Epoch: 180 Train Loss: 0.025 Train Acc: 0.992 Eval Loss: 0.617 Eval Acc: 0.877\n",
      "Epoch: 181 Train Loss: 0.025 Train Acc: 0.992 Eval Loss: 0.623 Eval Acc: 0.876\n",
      "Epoch: 182 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.618 Eval Acc: 0.878\n",
      "Epoch: 183 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.619 Eval Acc: 0.877\n",
      "Epoch: 184 Train Loss: 0.023 Train Acc: 0.993 Eval Loss: 0.626 Eval Acc: 0.877\n",
      "Epoch: 185 Train Loss: 0.023 Train Acc: 0.992 Eval Loss: 0.626 Eval Acc: 0.877\n",
      "Epoch: 186 Train Loss: 0.023 Train Acc: 0.993 Eval Loss: 0.626 Eval Acc: 0.877\n",
      "Epoch: 187 Train Loss: 0.022 Train Acc: 0.993 Eval Loss: 0.631 Eval Acc: 0.877\n",
      "Epoch: 188 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.633 Eval Acc: 0.877\n",
      "Epoch: 189 Train Loss: 0.022 Train Acc: 0.993 Eval Loss: 0.629 Eval Acc: 0.877\n",
      "Epoch: 190 Train Loss: 0.022 Train Acc: 0.992 Eval Loss: 0.635 Eval Acc: 0.878\n",
      "Epoch: 191 Train Loss: 0.021 Train Acc: 0.993 Eval Loss: 0.637 Eval Acc: 0.878\n",
      "Epoch: 192 Train Loss: 0.023 Train Acc: 0.992 Eval Loss: 0.632 Eval Acc: 0.879\n",
      "Epoch: 193 Train Loss: 0.023 Train Acc: 0.993 Eval Loss: 0.632 Eval Acc: 0.879\n",
      "Epoch: 194 Train Loss: 0.022 Train Acc: 0.993 Eval Loss: 0.633 Eval Acc: 0.876\n",
      "Epoch: 195 Train Loss: 0.022 Train Acc: 0.993 Eval Loss: 0.640 Eval Acc: 0.878\n",
      "Epoch: 196 Train Loss: 0.021 Train Acc: 0.993 Eval Loss: 0.640 Eval Acc: 0.877\n",
      "Epoch: 197 Train Loss: 0.022 Train Acc: 0.993 Eval Loss: 0.636 Eval Acc: 0.877\n",
      "Epoch: 198 Train Loss: 0.021 Train Acc: 0.993 Eval Loss: 0.643 Eval Acc: 0.877\n",
      "Epoch: 199 Train Loss: 0.021 Train Acc: 0.993 Eval Loss: 0.642 Eval Acc: 0.877\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "ResNet(\n",
      "  (conv1): ConvReLU2d(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (bn1): Identity()\n",
      "  (relu): Identity()\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n",
      "Training QAT Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apaddo/.local/lib/python3.9/site-packages/torch/ao/quantization/observer.py:177: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: -1 Eval Loss: 0.642 Eval Acc: 0.877\n",
      "Epoch: 000 Train Loss: 0.044 Train Acc: 0.985 Eval Loss: 0.679 Eval Acc: 0.868\n",
      "Epoch: 001 Train Loss: 0.054 Train Acc: 0.981 Eval Loss: 0.694 Eval Acc: 0.859\n",
      "Epoch: 002 Train Loss: 0.047 Train Acc: 0.984 Eval Loss: 0.669 Eval Acc: 0.868\n",
      "Epoch: 003 Train Loss: 0.042 Train Acc: 0.986 Eval Loss: 0.707 Eval Acc: 0.863\n",
      "Epoch: 004 Train Loss: 0.046 Train Acc: 0.983 Eval Loss: 0.702 Eval Acc: 0.865\n",
      "Epoch: 005 Train Loss: 0.047 Train Acc: 0.984 Eval Loss: 0.668 Eval Acc: 0.868\n",
      "Epoch: 006 Train Loss: 0.043 Train Acc: 0.985 Eval Loss: 0.678 Eval Acc: 0.869\n",
      "Epoch: 007 Train Loss: 0.044 Train Acc: 0.985 Eval Loss: 0.661 Eval Acc: 0.867\n",
      "Epoch: 008 Train Loss: 0.043 Train Acc: 0.985 Eval Loss: 0.673 Eval Acc: 0.868\n",
      "Epoch: 009 Train Loss: 0.039 Train Acc: 0.986 Eval Loss: 0.702 Eval Acc: 0.863\n",
      "Epoch: 010 Train Loss: 0.040 Train Acc: 0.985 Eval Loss: 0.690 Eval Acc: 0.865\n",
      "Epoch: 011 Train Loss: 0.039 Train Acc: 0.987 Eval Loss: 0.669 Eval Acc: 0.870\n",
      "Epoch: 012 Train Loss: 0.039 Train Acc: 0.987 Eval Loss: 0.695 Eval Acc: 0.866\n",
      "Epoch: 013 Train Loss: 0.038 Train Acc: 0.986 Eval Loss: 0.709 Eval Acc: 0.864\n",
      "Epoch: 014 Train Loss: 0.039 Train Acc: 0.986 Eval Loss: 0.704 Eval Acc: 0.866\n",
      "Epoch: 015 Train Loss: 0.037 Train Acc: 0.987 Eval Loss: 0.685 Eval Acc: 0.868\n",
      "Epoch: 016 Train Loss: 0.040 Train Acc: 0.986 Eval Loss: 0.682 Eval Acc: 0.865\n",
      "Epoch: 017 Train Loss: 0.038 Train Acc: 0.986 Eval Loss: 0.705 Eval Acc: 0.865\n",
      "Epoch: 018 Train Loss: 0.035 Train Acc: 0.988 Eval Loss: 0.706 Eval Acc: 0.867\n",
      "Epoch: 019 Train Loss: 0.032 Train Acc: 0.989 Eval Loss: 0.705 Eval Acc: 0.866\n",
      "Epoch: 020 Train Loss: 0.037 Train Acc: 0.987 Eval Loss: 0.690 Eval Acc: 0.870\n",
      "Epoch: 021 Train Loss: 0.033 Train Acc: 0.988 Eval Loss: 0.721 Eval Acc: 0.862\n",
      "Epoch: 022 Train Loss: 0.033 Train Acc: 0.988 Eval Loss: 0.695 Eval Acc: 0.869\n",
      "Epoch: 023 Train Loss: 0.030 Train Acc: 0.989 Eval Loss: 0.701 Eval Acc: 0.867\n",
      "Epoch: 024 Train Loss: 0.031 Train Acc: 0.989 Eval Loss: 0.696 Eval Acc: 0.866\n",
      "Epoch: 025 Train Loss: 0.031 Train Acc: 0.989 Eval Loss: 0.695 Eval Acc: 0.867\n",
      "Epoch: 026 Train Loss: 0.030 Train Acc: 0.990 Eval Loss: 0.704 Eval Acc: 0.868\n",
      "Epoch: 027 Train Loss: 0.032 Train Acc: 0.989 Eval Loss: 0.707 Eval Acc: 0.869\n",
      "Epoch: 028 Train Loss: 0.032 Train Acc: 0.989 Eval Loss: 0.698 Eval Acc: 0.869\n",
      "Epoch: 029 Train Loss: 0.033 Train Acc: 0.988 Eval Loss: 0.703 Eval Acc: 0.872\n",
      "Epoch: 030 Train Loss: 0.031 Train Acc: 0.990 Eval Loss: 0.703 Eval Acc: 0.865\n",
      "Epoch: 031 Train Loss: 0.033 Train Acc: 0.988 Eval Loss: 0.700 Eval Acc: 0.870\n",
      "Epoch: 032 Train Loss: 0.029 Train Acc: 0.990 Eval Loss: 0.717 Eval Acc: 0.870\n",
      "Epoch: 033 Train Loss: 0.029 Train Acc: 0.989 Eval Loss: 0.704 Eval Acc: 0.868\n",
      "Epoch: 034 Train Loss: 0.028 Train Acc: 0.990 Eval Loss: 0.694 Eval Acc: 0.869\n",
      "Epoch: 035 Train Loss: 0.027 Train Acc: 0.991 Eval Loss: 0.728 Eval Acc: 0.867\n",
      "Epoch: 036 Train Loss: 0.029 Train Acc: 0.990 Eval Loss: 0.717 Eval Acc: 0.867\n",
      "Epoch: 037 Train Loss: 0.033 Train Acc: 0.988 Eval Loss: 0.713 Eval Acc: 0.868\n",
      "Epoch: 038 Train Loss: 0.032 Train Acc: 0.989 Eval Loss: 0.730 Eval Acc: 0.864\n",
      "Epoch: 039 Train Loss: 0.028 Train Acc: 0.990 Eval Loss: 0.720 Eval Acc: 0.867\n",
      "Epoch: 040 Train Loss: 0.028 Train Acc: 0.990 Eval Loss: 0.727 Eval Acc: 0.866\n",
      "Epoch: 041 Train Loss: 0.028 Train Acc: 0.990 Eval Loss: 0.696 Eval Acc: 0.871\n",
      "Epoch: 042 Train Loss: 0.025 Train Acc: 0.991 Eval Loss: 0.736 Eval Acc: 0.869\n",
      "Epoch: 043 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.723 Eval Acc: 0.873\n",
      "Epoch: 044 Train Loss: 0.027 Train Acc: 0.990 Eval Loss: 0.712 Eval Acc: 0.870\n",
      "Epoch: 045 Train Loss: 0.024 Train Acc: 0.991 Eval Loss: 0.727 Eval Acc: 0.867\n",
      "Epoch: 046 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.723 Eval Acc: 0.871\n",
      "Epoch: 047 Train Loss: 0.023 Train Acc: 0.992 Eval Loss: 0.726 Eval Acc: 0.869\n",
      "Epoch: 048 Train Loss: 0.028 Train Acc: 0.990 Eval Loss: 0.723 Eval Acc: 0.870\n",
      "Epoch: 049 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.717 Eval Acc: 0.871\n",
      "Epoch: 050 Train Loss: 0.025 Train Acc: 0.991 Eval Loss: 0.737 Eval Acc: 0.867\n",
      "Epoch: 051 Train Loss: 0.025 Train Acc: 0.991 Eval Loss: 0.748 Eval Acc: 0.867\n",
      "Epoch: 052 Train Loss: 0.027 Train Acc: 0.991 Eval Loss: 0.733 Eval Acc: 0.867\n",
      "Epoch: 053 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.736 Eval Acc: 0.869\n",
      "Epoch: 054 Train Loss: 0.025 Train Acc: 0.992 Eval Loss: 0.723 Eval Acc: 0.873\n",
      "Epoch: 055 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.726 Eval Acc: 0.869\n",
      "Epoch: 056 Train Loss: 0.021 Train Acc: 0.993 Eval Loss: 0.727 Eval Acc: 0.871\n",
      "Epoch: 057 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.730 Eval Acc: 0.868\n",
      "Epoch: 058 Train Loss: 0.022 Train Acc: 0.992 Eval Loss: 0.726 Eval Acc: 0.870\n",
      "Epoch: 059 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.740 Eval Acc: 0.870\n",
      "Epoch: 060 Train Loss: 0.022 Train Acc: 0.992 Eval Loss: 0.740 Eval Acc: 0.868\n",
      "Epoch: 061 Train Loss: 0.024 Train Acc: 0.992 Eval Loss: 0.736 Eval Acc: 0.868\n",
      "Epoch: 062 Train Loss: 0.021 Train Acc: 0.993 Eval Loss: 0.728 Eval Acc: 0.870\n",
      "Epoch: 063 Train Loss: 0.023 Train Acc: 0.992 Eval Loss: 0.745 Eval Acc: 0.868\n",
      "Epoch: 064 Train Loss: 0.023 Train Acc: 0.992 Eval Loss: 0.733 Eval Acc: 0.872\n",
      "Epoch: 065 Train Loss: 0.025 Train Acc: 0.992 Eval Loss: 0.730 Eval Acc: 0.871\n",
      "Epoch: 066 Train Loss: 0.023 Train Acc: 0.993 Eval Loss: 0.740 Eval Acc: 0.867\n",
      "Epoch: 067 Train Loss: 0.026 Train Acc: 0.991 Eval Loss: 0.737 Eval Acc: 0.871\n",
      "Epoch: 068 Train Loss: 0.023 Train Acc: 0.992 Eval Loss: 0.740 Eval Acc: 0.870\n",
      "Epoch: 069 Train Loss: 0.023 Train Acc: 0.992 Eval Loss: 0.757 Eval Acc: 0.870\n",
      "Epoch: 070 Train Loss: 0.022 Train Acc: 0.992 Eval Loss: 0.732 Eval Acc: 0.871\n",
      "Epoch: 071 Train Loss: 0.018 Train Acc: 0.994 Eval Loss: 0.759 Eval Acc: 0.868\n",
      "Epoch: 072 Train Loss: 0.019 Train Acc: 0.993 Eval Loss: 0.769 Eval Acc: 0.863\n",
      "Epoch: 073 Train Loss: 0.021 Train Acc: 0.993 Eval Loss: 0.750 Eval Acc: 0.871\n",
      "Epoch: 074 Train Loss: 0.023 Train Acc: 0.992 Eval Loss: 0.758 Eval Acc: 0.868\n",
      "Epoch: 075 Train Loss: 0.023 Train Acc: 0.992 Eval Loss: 0.727 Eval Acc: 0.873\n",
      "Epoch: 076 Train Loss: 0.020 Train Acc: 0.993 Eval Loss: 0.778 Eval Acc: 0.864\n",
      "Epoch: 077 Train Loss: 0.022 Train Acc: 0.992 Eval Loss: 0.760 Eval Acc: 0.868\n",
      "Epoch: 078 Train Loss: 0.021 Train Acc: 0.992 Eval Loss: 0.730 Eval Acc: 0.870\n",
      "Epoch: 079 Train Loss: 0.023 Train Acc: 0.992 Eval Loss: 0.729 Eval Acc: 0.871\n",
      "Epoch: 080 Train Loss: 0.021 Train Acc: 0.993 Eval Loss: 0.729 Eval Acc: 0.870\n",
      "Epoch: 081 Train Loss: 0.018 Train Acc: 0.994 Eval Loss: 0.749 Eval Acc: 0.868\n",
      "Epoch: 082 Train Loss: 0.018 Train Acc: 0.994 Eval Loss: 0.759 Eval Acc: 0.869\n",
      "Epoch: 083 Train Loss: 0.021 Train Acc: 0.993 Eval Loss: 0.766 Eval Acc: 0.869\n",
      "Epoch: 084 Train Loss: 0.021 Train Acc: 0.993 Eval Loss: 0.765 Eval Acc: 0.866\n",
      "Epoch: 085 Train Loss: 0.020 Train Acc: 0.993 Eval Loss: 0.744 Eval Acc: 0.869\n",
      "Epoch: 086 Train Loss: 0.019 Train Acc: 0.994 Eval Loss: 0.754 Eval Acc: 0.871\n",
      "Epoch: 087 Train Loss: 0.020 Train Acc: 0.993 Eval Loss: 0.754 Eval Acc: 0.868\n",
      "Epoch: 088 Train Loss: 0.017 Train Acc: 0.994 Eval Loss: 0.754 Eval Acc: 0.873\n",
      "Epoch: 089 Train Loss: 0.018 Train Acc: 0.994 Eval Loss: 0.770 Eval Acc: 0.870\n",
      "Epoch: 090 Train Loss: 0.017 Train Acc: 0.994 Eval Loss: 0.776 Eval Acc: 0.868\n",
      "Epoch: 091 Train Loss: 0.019 Train Acc: 0.994 Eval Loss: 0.770 Eval Acc: 0.870\n",
      "Epoch: 092 Train Loss: 0.019 Train Acc: 0.994 Eval Loss: 0.771 Eval Acc: 0.868\n",
      "Epoch: 093 Train Loss: 0.019 Train Acc: 0.994 Eval Loss: 0.741 Eval Acc: 0.875\n",
      "Epoch: 094 Train Loss: 0.018 Train Acc: 0.994 Eval Loss: 0.776 Eval Acc: 0.872\n",
      "Epoch: 095 Train Loss: 0.016 Train Acc: 0.994 Eval Loss: 0.796 Eval Acc: 0.867\n",
      "Epoch: 096 Train Loss: 0.019 Train Acc: 0.993 Eval Loss: 0.782 Eval Acc: 0.869\n",
      "Epoch: 097 Train Loss: 0.020 Train Acc: 0.993 Eval Loss: 0.794 Eval Acc: 0.866\n",
      "Epoch: 098 Train Loss: 0.017 Train Acc: 0.994 Eval Loss: 0.772 Eval Acc: 0.870\n",
      "Epoch: 099 Train Loss: 0.016 Train Acc: 0.994 Eval Loss: 0.776 Eval Acc: 0.868\n",
      "Epoch: 100 Train Loss: 0.011 Train Acc: 0.997 Eval Loss: 0.753 Eval Acc: 0.872\n",
      "Epoch: 101 Train Loss: 0.010 Train Acc: 0.997 Eval Loss: 0.753 Eval Acc: 0.874\n",
      "Epoch: 102 Train Loss: 0.009 Train Acc: 0.997 Eval Loss: 0.751 Eval Acc: 0.874\n",
      "Epoch: 103 Train Loss: 0.008 Train Acc: 0.997 Eval Loss: 0.749 Eval Acc: 0.876\n",
      "Epoch: 104 Train Loss: 0.007 Train Acc: 0.998 Eval Loss: 0.749 Eval Acc: 0.876\n",
      "Epoch: 105 Train Loss: 0.007 Train Acc: 0.998 Eval Loss: 0.750 Eval Acc: 0.875\n",
      "Epoch: 106 Train Loss: 0.008 Train Acc: 0.998 Eval Loss: 0.750 Eval Acc: 0.877\n",
      "Epoch: 107 Train Loss: 0.008 Train Acc: 0.998 Eval Loss: 0.747 Eval Acc: 0.876\n",
      "Epoch: 108 Train Loss: 0.007 Train Acc: 0.998 Eval Loss: 0.749 Eval Acc: 0.876\n",
      "Epoch: 109 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.752 Eval Acc: 0.877\n",
      "Epoch: 110 Train Loss: 0.007 Train Acc: 0.998 Eval Loss: 0.750 Eval Acc: 0.875\n",
      "Epoch: 111 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.748 Eval Acc: 0.877\n",
      "Epoch: 112 Train Loss: 0.007 Train Acc: 0.998 Eval Loss: 0.750 Eval Acc: 0.875\n",
      "Epoch: 113 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.752 Eval Acc: 0.876\n",
      "Epoch: 114 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.750 Eval Acc: 0.877\n",
      "Epoch: 115 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.751 Eval Acc: 0.876\n",
      "Epoch: 116 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.750 Eval Acc: 0.876\n",
      "Epoch: 117 Train Loss: 0.007 Train Acc: 0.998 Eval Loss: 0.752 Eval Acc: 0.876\n",
      "Epoch: 118 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.753 Eval Acc: 0.877\n",
      "Epoch: 119 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.757 Eval Acc: 0.876\n",
      "Epoch: 120 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.758 Eval Acc: 0.875\n",
      "Epoch: 121 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.756 Eval Acc: 0.877\n",
      "Epoch: 122 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.757 Eval Acc: 0.875\n",
      "Epoch: 123 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.755 Eval Acc: 0.875\n",
      "Epoch: 124 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.756 Eval Acc: 0.876\n",
      "Epoch: 125 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.760 Eval Acc: 0.876\n",
      "Epoch: 126 Train Loss: 0.005 Train Acc: 0.998 Eval Loss: 0.760 Eval Acc: 0.876\n",
      "Epoch: 127 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.757 Eval Acc: 0.877\n",
      "Epoch: 128 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.757 Eval Acc: 0.877\n",
      "Epoch: 129 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.762 Eval Acc: 0.876\n",
      "Epoch: 130 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.763 Eval Acc: 0.875\n",
      "Epoch: 131 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.768 Eval Acc: 0.877\n",
      "Epoch: 132 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.759 Eval Acc: 0.877\n",
      "Epoch: 133 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.765 Eval Acc: 0.876\n",
      "Epoch: 134 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.764 Eval Acc: 0.876\n",
      "Epoch: 135 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.763 Eval Acc: 0.876\n",
      "Epoch: 136 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.765 Eval Acc: 0.876\n",
      "Epoch: 137 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.764 Eval Acc: 0.876\n",
      "Epoch: 138 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.764 Eval Acc: 0.876\n",
      "Epoch: 139 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.766 Eval Acc: 0.876\n",
      "Epoch: 140 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.765 Eval Acc: 0.876\n",
      "Epoch: 141 Train Loss: 0.005 Train Acc: 0.998 Eval Loss: 0.765 Eval Acc: 0.875\n",
      "Epoch: 142 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.770 Eval Acc: 0.875\n",
      "Epoch: 143 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.766 Eval Acc: 0.875\n",
      "Epoch: 144 Train Loss: 0.005 Train Acc: 0.998 Eval Loss: 0.766 Eval Acc: 0.876\n",
      "Epoch: 145 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.766 Eval Acc: 0.876\n",
      "Epoch: 146 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.768 Eval Acc: 0.876\n",
      "Epoch: 147 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.768 Eval Acc: 0.877\n",
      "Epoch: 148 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.876\n",
      "Epoch: 149 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.772 Eval Acc: 0.875\n",
      "Epoch: 150 Train Loss: 0.005 Train Acc: 0.998 Eval Loss: 0.771 Eval Acc: 0.875\n",
      "Epoch: 151 Train Loss: 0.006 Train Acc: 0.998 Eval Loss: 0.771 Eval Acc: 0.875\n",
      "Epoch: 152 Train Loss: 0.005 Train Acc: 0.998 Eval Loss: 0.771 Eval Acc: 0.875\n",
      "Epoch: 153 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.771 Eval Acc: 0.875\n",
      "Epoch: 154 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.771 Eval Acc: 0.875\n",
      "Epoch: 155 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.875\n",
      "Epoch: 156 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.771 Eval Acc: 0.875\n",
      "Epoch: 157 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.771 Eval Acc: 0.875\n",
      "Epoch: 158 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.771 Eval Acc: 0.876\n",
      "Epoch: 159 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.771 Eval Acc: 0.876\n",
      "Epoch: 160 Train Loss: 0.005 Train Acc: 0.998 Eval Loss: 0.771 Eval Acc: 0.876\n",
      "Epoch: 161 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.771 Eval Acc: 0.876\n",
      "Epoch: 162 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.876\n",
      "Epoch: 163 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.876\n",
      "Epoch: 164 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.876\n",
      "Epoch: 165 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.876\n",
      "Epoch: 166 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.876\n",
      "Epoch: 167 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.876\n",
      "Epoch: 168 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.876\n",
      "Epoch: 169 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.771 Eval Acc: 0.875\n",
      "Epoch: 170 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.771 Eval Acc: 0.875\n",
      "Epoch: 171 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.771 Eval Acc: 0.875\n",
      "Epoch: 172 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.771 Eval Acc: 0.875\n",
      "Epoch: 173 Train Loss: 0.005 Train Acc: 0.998 Eval Loss: 0.771 Eval Acc: 0.875\n",
      "Epoch: 174 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.771 Eval Acc: 0.875\n",
      "Epoch: 175 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.771 Eval Acc: 0.876\n",
      "Epoch: 176 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.875\n",
      "Epoch: 177 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.875\n",
      "Epoch: 178 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.875\n",
      "Epoch: 179 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.876\n",
      "Epoch: 180 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.772 Eval Acc: 0.875\n",
      "Epoch: 181 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.773 Eval Acc: 0.876\n",
      "Epoch: 182 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.773 Eval Acc: 0.876\n",
      "Epoch: 183 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.773 Eval Acc: 0.876\n",
      "Epoch: 184 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.773 Eval Acc: 0.876\n",
      "Epoch: 185 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.773 Eval Acc: 0.875\n",
      "Epoch: 186 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.773 Eval Acc: 0.875\n",
      "Epoch: 187 Train Loss: 0.005 Train Acc: 0.998 Eval Loss: 0.773 Eval Acc: 0.876\n",
      "Epoch: 188 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.773 Eval Acc: 0.876\n",
      "Epoch: 189 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.773 Eval Acc: 0.875\n",
      "Epoch: 190 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.774 Eval Acc: 0.875\n",
      "Epoch: 191 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.773 Eval Acc: 0.875\n",
      "Epoch: 192 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.774 Eval Acc: 0.875\n",
      "Epoch: 193 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.773 Eval Acc: 0.876\n",
      "Epoch: 194 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.773 Eval Acc: 0.876\n",
      "Epoch: 195 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.773 Eval Acc: 0.876\n",
      "Epoch: 196 Train Loss: 0.005 Train Acc: 0.999 Eval Loss: 0.774 Eval Acc: 0.876\n",
      "Epoch: 197 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.774 Eval Acc: 0.876\n",
      "Epoch: 198 Train Loss: 0.005 Train Acc: 0.998 Eval Loss: 0.774 Eval Acc: 0.876\n",
      "Epoch: 199 Train Loss: 0.004 Train Acc: 0.999 Eval Loss: 0.774 Eval Acc: 0.876\n",
      "QuantizedResNet18(\n",
      "  (quant): Quantize(scale=tensor([0.0374]), zero_point=tensor([57]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      "  (model_fp32): ResNet(\n",
      "    (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.07864463329315186, zero_point=0, padding=(3, 3))\n",
      "    (bn1): Identity()\n",
      "    (relu): Identity()\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.03589373081922531, zero_point=0, padding=(1, 1))\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.092372365295887, zero_point=71, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (skip_add): QFunctional(\n",
      "          scale=0.11383531242609024, zero_point=53\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.032582838088274, zero_point=0, padding=(1, 1))\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.085746631026268, zero_point=69, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (skip_add): QFunctional(\n",
      "          scale=0.12295900285243988, zero_point=51\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.0294225811958313, zero_point=0, padding=(1, 1))\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.07733430713415146, zero_point=66, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (downsample): Sequential(\n",
      "          (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.056032855063676834, zero_point=63)\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (skip_add): QFunctional(\n",
      "          scale=0.094465471804142, zero_point=63\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.0322563536465168, zero_point=0, padding=(1, 1))\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.0739070251584053, zero_point=67, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (skip_add): QFunctional(\n",
      "          scale=0.096784308552742, zero_point=53\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.02507234364748001, zero_point=0, padding=(1, 1))\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.04719649255275726, zero_point=71, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (downsample): Sequential(\n",
      "          (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.02884783409535885, zero_point=58)\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (skip_add): QFunctional(\n",
      "          scale=0.05486360564827919, zero_point=68\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.005154894664883614, zero_point=0, padding=(1, 1))\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.02670244872570038, zero_point=77, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (skip_add): QFunctional(\n",
      "          scale=0.038270510733127594, zero_point=54\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.010306506417691708, zero_point=0, padding=(1, 1))\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.030723026022315025, zero_point=61, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (downsample): Sequential(\n",
      "          (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.0428728312253952, zero_point=53)\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (skip_add): QFunctional(\n",
      "          scale=0.05433397367596626, zero_point=50\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.003570857457816601, zero_point=0, padding=(1, 1))\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.021238086745142937, zero_point=65, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (skip_add): QFunctional(\n",
      "          scale=0.04451192170381546, zero_point=33\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.37065622210502625, zero_point=44, qscheme=torch.per_channel_affine)\n",
      "  )\n",
      ")\n",
      "FP32 evaluation accuracy: 0.877\n",
      "INT8 evaluation accuracy: 0.874\n",
      "FP32 CPU Inference Latency: 31.74 ms / sample\n",
      "FP32 CUDA Inference Latency: 5.31 ms / sample\n",
      "INT8 CPU Inference Latency: 2.76 ms / sample\n",
      "INT8 JIT CPU Inference Latency: 1.61 ms / sample\n"
     ]
    }
   ],
   "source": [
    "def set_random_seeds(random_seed=0):\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "def prepare_dataloader(num_workers=8, train_batch_size=128, eval_batch_size=256):\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    train_set = torchvision.datasets.CIFAR10(root=\"data\", train=True, download=True, transform=train_transform) \n",
    "    # We will use test set for validation and test in this project.\n",
    "    # Do not use test set for validation in practice!\n",
    "    test_set = torchvision.datasets.CIFAR10(root=\"data\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "    train_sampler = torch.utils.data.RandomSampler(train_set)\n",
    "    test_sampler = torch.utils.data.SequentialSampler(test_set)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set, batch_size=train_batch_size,\n",
    "        sampler=train_sampler, num_workers=num_workers)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_set, batch_size=eval_batch_size,\n",
    "        sampler=test_sampler, num_workers=num_workers)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def evaluate_model(model, test_loader, device, criterion=None):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        if criterion is not None:\n",
    "            loss = criterion(outputs, labels).item()\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    eval_loss = running_loss / len(test_loader.dataset)\n",
    "    eval_accuracy = running_corrects / len(test_loader.dataset)\n",
    "\n",
    "    return eval_loss, eval_accuracy\n",
    "\n",
    "def train_model(model, train_loader, test_loader, device, learning_rate=1e-1, num_epochs=200):\n",
    "\n",
    "    # The training configurations were not carefully selected.\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # It seems that SGD optimizer is better than Adam optimizer for ResNet18 training on CIFAR10.\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1, last_epoch=-1)\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = evaluate_model(model=model, test_loader=test_loader, device=device, criterion=criterion)\n",
    "    print(\"Epoch: {:02d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(-1, eval_loss, eval_accuracy))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        eval_loss, eval_accuracy = evaluate_model(model=model, test_loader=test_loader, device=device, criterion=criterion)\n",
    "\n",
    "        # Set learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        print(\"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(epoch, train_loss, train_accuracy, eval_loss, eval_accuracy))\n",
    "\n",
    "    return model\n",
    "\n",
    "def calibrate_model(model, loader, device=torch.device(\"cuda:5\")):\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        _ = model(inputs)\n",
    "\n",
    "def measure_inference_latency(model,\n",
    "                              device,\n",
    "                              input_size=(1, 3, 32, 32),\n",
    "                              num_samples=100,\n",
    "                              num_warmups=10):\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    x = torch.rand(size=input_size).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_warmups):\n",
    "            _ = model(x)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_samples):\n",
    "            _ = model(x)\n",
    "            torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_time_ave = elapsed_time / num_samples\n",
    "\n",
    "    return elapsed_time_ave\n",
    "\n",
    "def save_model(model, model_dir, model_filename):\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "    torch.save(model.state_dict(), model_filepath)\n",
    "\n",
    "def load_model(model, model_filepath, device):\n",
    "\n",
    "    model.load_state_dict(torch.load(model_filepath, map_location=device))\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_torchscript_model(model, model_dir, model_filename):\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "    torch.jit.save(torch.jit.script(model), model_filepath)\n",
    "\n",
    "def load_torchscript_model(model_filepath, device):\n",
    "\n",
    "    model = torch.jit.load(model_filepath, map_location=device)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model(num_classes=10):\n",
    "\n",
    "    # The number of channels in ResNet18 is divisible by 8.\n",
    "    # This is required for fast GEMM integer matrix multiplication.\n",
    "    # model = torchvision.models.resnet18(pretrained=False)\n",
    "    model = resnet18(num_classes=num_classes, pretrained=False)\n",
    "\n",
    "    # We would use the pretrained ResNet18 as a feature extractor.\n",
    "    # for param in model.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    \n",
    "    # Modify the last FC layer\n",
    "    # num_features = model.fc.in_features\n",
    "    # model.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "    return model\n",
    "\n",
    "class QuantizedResNet18(nn.Module):\n",
    "    def __init__(self, model_fp32):\n",
    "        super(QuantizedResNet18, self).__init__()\n",
    "        # QuantStub converts tensors from floating point to quantized.\n",
    "        # This will only be used for inputs.\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        # DeQuantStub converts tensors from quantized to floating point.\n",
    "        # This will only be used for outputs.\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        # FP32 model\n",
    "        self.model_fp32 = model_fp32\n",
    "\n",
    "    def forward(self, x):\n",
    "        # manually specify where tensors will be converted from floating\n",
    "        # point to quantized in the quantized model\n",
    "        x = self.quant(x)\n",
    "        x = self.model_fp32(x)\n",
    "        # manually specify where tensors will be converted from quantized\n",
    "        # to floating point in the quantized model\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "def model_equivalence(model_1, model_2, device, rtol=1e-05, atol=1e-08, num_tests=100, input_size=(1,3,32,32)):\n",
    "\n",
    "    model_1.to(device)\n",
    "    model_2.to(device)\n",
    "\n",
    "    for _ in range(num_tests):\n",
    "        x = torch.rand(size=input_size).to(device)\n",
    "        y1 = model_1(x).detach().cpu().numpy()\n",
    "        y2 = model_2(x).detach().cpu().numpy()\n",
    "        if np.allclose(a=y1, b=y2, rtol=rtol, atol=atol, equal_nan=False) == False:\n",
    "            print(\"Model equivalence test sample failed: \")\n",
    "            print(y1)\n",
    "            print(y2)\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "\n",
    "    random_seed = 0\n",
    "    num_classes = 10\n",
    "    cuda_device = torch.device(\"cuda:1\")\n",
    "    cpu_device = torch.device(\"cpu:0\")\n",
    "\n",
    "    model_dir = \"saved_models\"\n",
    "    model_filename = \"resnet18_cifar10.pt\"\n",
    "    quantized_model_filename = \"resnet18_quantized_cifar10.pt\"\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "    quantized_model_filepath = os.path.join(model_dir, quantized_model_filename)\n",
    "\n",
    "    set_random_seeds(random_seed=random_seed)\n",
    "\n",
    "    # Create an untrained model.\n",
    "    model = create_model(num_classes=num_classes)\n",
    "\n",
    "    train_loader, test_loader = prepare_dataloader(num_workers=8, train_batch_size=128, eval_batch_size=256)\n",
    "    \n",
    "    # Train model.\n",
    "    print(\"Training Model...\")\n",
    "    model = train_model(model=model, train_loader=train_loader, test_loader=test_loader, device=cuda_device, learning_rate=1e-1, num_epochs=200)\n",
    "    # Save model.\n",
    "    save_model(model=model, model_dir=model_dir, model_filename=model_filename)\n",
    "    # Load a pretrained model.\n",
    "    model = load_model(model=model, model_filepath=model_filepath, device=cuda_device)\n",
    "    # Move the model to CPU since static quantization does not support CUDA currently.\n",
    "    model.to(cpu_device)\n",
    "    # Make a copy of the model for layer fusion\n",
    "    fused_model = copy.deepcopy(model)\n",
    "\n",
    "    model.train()\n",
    "    # The model has to be switched to training mode before any layer fusion.\n",
    "    # Otherwise the quantization aware training will not work correctly.\n",
    "    fused_model.train()\n",
    "    \n",
    "    # Model and fused model should be equivalent.\n",
    "    model.eval()\n",
    "    fused_model.eval()\n",
    "\n",
    "    # Fuse the model in place rather manually.\n",
    "    fused_model = torch.quantization.fuse_modules(fused_model, [[\"conv1\", \"bn1\", \"relu\"]], inplace=True)\n",
    "    for module_name, module in fused_model.named_children():\n",
    "        if \"layer\" in module_name:\n",
    "            for basic_block_name, basic_block in module.named_children():\n",
    "                torch.quantization.fuse_modules(basic_block, [[\"conv1\", \"bn1\", \"relu1\"], [\"conv2\", \"bn2\"]], inplace=True)\n",
    "                for sub_block_name, sub_block in basic_block.named_children():\n",
    "                    if sub_block_name == \"downsample\":\n",
    "                        torch.quantization.fuse_modules(sub_block, [[\"0\", \"1\"]], inplace=True)\n",
    "\n",
    "    # Print FP32 model.\n",
    "    print(model)\n",
    "    # Print fused model.\n",
    "    print(fused_model)\n",
    "\n",
    "\n",
    "    assert model_equivalence(model_1=model, model_2=fused_model, device=cpu_device, rtol=1e-03, atol=1e-06, num_tests=100, input_size=(1,3,32,32)), \"Fused model is not equivalent to the original model!\"\n",
    "\n",
    "    # Prepare the model for quantization aware training. This inserts observers in\n",
    "    # the model that will observe activation tensors during calibration.\n",
    "    quantized_model = QuantizedResNet18(model_fp32=fused_model)\n",
    "    # Using un-fused model will fail.\n",
    "    # Because there is no quantized layer implementation for a single batch normalization layer.\n",
    "    # quantized_model = QuantizedResNet18(model_fp32=model)\n",
    "    # Select quantization schemes from \n",
    "    # https://pytorch.org/docs/stable/quantization-support.html\n",
    "    quantization_config = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "    # Custom quantization configurations\n",
    "    # quantization_config = torch.quantization.default_qconfig\n",
    "    # quantization_config = torch.quantization.QConfig(activation=torch.quantization.MinMaxObserver.with_args(dtype=torch.quint8), weight=torch.quantization.MinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
    "\n",
    "    quantized_model.qconfig = quantization_config\n",
    "    \n",
    "    # Print quantization configurations\n",
    "    print(quantized_model.qconfig)\n",
    "\n",
    "    # https://pytorch.org/docs/stable/_modules/torch/quantization/quantize.html#prepare_qat\n",
    "    torch.quantization.prepare_qat(quantized_model, inplace=True)\n",
    "\n",
    "    # # Use training data for calibration.\n",
    "    print(\"Training QAT Model...\")\n",
    "    quantized_model.train()\n",
    "    train_model(model=quantized_model, train_loader=train_loader, test_loader=test_loader, device=cuda_device, learning_rate=1e-3, num_epochs=200)\n",
    "    quantized_model.to(cpu_device)\n",
    "\n",
    "    # Using high-level static quantization wrapper\n",
    "    # The above steps, including torch.quantization.prepare, calibrate_model, and torch.quantization.convert, are also equivalent to\n",
    "    # quantized_model = torch.quantization.quantize_qat(model=quantized_model, run_fn=train_model, run_args=[train_loader, test_loader, cuda_device], mapping=None, inplace=False)\n",
    "\n",
    "    quantized_model = torch.quantization.convert(quantized_model, inplace=True)\n",
    "\n",
    "    quantized_model.eval()\n",
    "\n",
    "    # Print quantized model.\n",
    "    print(quantized_model)\n",
    "\n",
    "    # Save quantized model.\n",
    "    save_torchscript_model(model=quantized_model, model_dir=model_dir, model_filename=quantized_model_filename)\n",
    "\n",
    "    # Load quantized model.\n",
    "    quantized_jit_model = load_torchscript_model(model_filepath=quantized_model_filepath, device=cpu_device)\n",
    "\n",
    "    _, fp32_eval_accuracy = evaluate_model(model=model, test_loader=test_loader, device=cpu_device, criterion=None)\n",
    "    _, int8_eval_accuracy = evaluate_model(model=quantized_jit_model, test_loader=test_loader, device=cpu_device, criterion=None)\n",
    "\n",
    "    # Skip this assertion since the values might deviate a lot.\n",
    "    # assert model_equivalence(model_1=model, model_2=quantized_jit_model, device=cpu_device, rtol=1e-01, atol=1e-02, num_tests=100, input_size=(1,3,32,32)), \"Quantized model deviates from the original model too much!\"\n",
    "\n",
    "    print(\"FP32 evaluation accuracy: {:.3f}\".format(fp32_eval_accuracy))\n",
    "    print(\"INT8 evaluation accuracy: {:.3f}\".format(int8_eval_accuracy))\n",
    "\n",
    "    fp32_cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "    int8_cpu_inference_latency = measure_inference_latency(model=quantized_model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "    int8_jit_cpu_inference_latency = measure_inference_latency(model=quantized_jit_model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "    fp32_gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "    \n",
    "    print(\"FP32 CPU Inference Latency: {:.2f} ms / sample\".format(fp32_cpu_inference_latency * 1000))\n",
    "    print(\"FP32 CUDA Inference Latency: {:.2f} ms / sample\".format(fp32_gpu_inference_latency * 1000))\n",
    "    print(\"INT8 CPU Inference Latency: {:.2f} ms / sample\".format(int8_cpu_inference_latency * 1000))\n",
    "    print(\"INT8 JIT CPU Inference Latency: {:.2f} ms / sample\".format(int8_jit_cpu_inference_latency * 1000))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c89e7516",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The archive ILSVRC2012_img_train.tar is not present in the root directory or is corrupted. You need to download it externally and place it in data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 374>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINT8 JIT CPU Inference Latency: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m ms / sample\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(int8_jit_cpu_inference_latency \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Create an untrained model.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\n\u001b[0;32m--> 270\u001b[0m train_loader, test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Train model.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mprepare_dataloader\u001b[0;34m(num_workers, train_batch_size, eval_batch_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m train_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     12\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mRandomCrop(\u001b[38;5;241m32\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m     13\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mRandomHorizontalFlip(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m), std\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m))\n\u001b[1;32m     17\u001b[0m ])\n\u001b[1;32m     19\u001b[0m test_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     20\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m), std\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m))\n\u001b[1;32m     23\u001b[0m ])\n\u001b[0;32m---> 25\u001b[0m train_set \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_transform\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# We will use test set for validation and test in this project.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Do not use test set for validation in practice!\u001b[39;00m\n\u001b[1;32m     28\u001b[0m test_set \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mImageNet(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtest_transform)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/datasets/imagenet.py:46\u001b[0m, in \u001b[0;36mImageNet.__init__\u001b[0;34m(self, root, split, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m root \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(root)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;241m=\u001b[39m verify_str_arg(split, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_archives\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m wnid_to_classes \u001b[38;5;241m=\u001b[39m load_meta_file(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/datasets/imagenet.py:63\u001b[0m, in \u001b[0;36mImageNet.parse_archives\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_folder):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43mparse_train_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     65\u001b[0m         parse_val_archive(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/datasets/imagenet.py:169\u001b[0m, in \u001b[0;36mparse_train_archive\u001b[0;34m(root, file, folder)\u001b[0m\n\u001b[1;32m    166\u001b[0m     file \u001b[38;5;241m=\u001b[39m archive_meta[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    167\u001b[0m md5 \u001b[38;5;241m=\u001b[39m archive_meta[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 169\u001b[0m \u001b[43m_verify_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m train_root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, folder)\n\u001b[1;32m    172\u001b[0m extract_archive(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, file), train_root)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/datasets/imagenet.py:96\u001b[0m, in \u001b[0;36m_verify_archive\u001b[0;34m(root, file, md5)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_integrity(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, file), md5):\n\u001b[1;32m     92\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe archive \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is not present in the root directory or is corrupted. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to download it externally and place it in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     )\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(file, root))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The archive ILSVRC2012_img_train.tar is not present in the root directory or is corrupted. You need to download it externally and place it in data."
     ]
    }
   ],
   "source": [
    "def set_random_seeds(random_seed=0):\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "def prepare_dataloader(num_workers=8, train_batch_size=128, eval_batch_size=256):\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    train_set = torchvision.datasets.ImageNet(root=\"data\", train=True, download=True, transform=train_transform) \n",
    "    # We will use test set for validation and test in this project.\n",
    "    # Do not use test set for validation in practice!\n",
    "    test_set = torchvision.datasets.ImageNet(root=\"data\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "    train_sampler = torch.utils.data.RandomSampler(train_set)\n",
    "    test_sampler = torch.utils.data.SequentialSampler(test_set)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set, batch_size=train_batch_size,\n",
    "        sampler=train_sampler, num_workers=num_workers)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_set, batch_size=eval_batch_size,\n",
    "        sampler=test_sampler, num_workers=num_workers)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def evaluate_model(model, test_loader, device, criterion=None):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        if criterion is not None:\n",
    "            loss = criterion(outputs, labels).item()\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    eval_loss = running_loss / len(test_loader.dataset)\n",
    "    eval_accuracy = running_corrects / len(test_loader.dataset)\n",
    "\n",
    "    return eval_loss, eval_accuracy\n",
    "\n",
    "def train_model(model, train_loader, test_loader, device, learning_rate=1e-1, num_epochs=200):\n",
    "\n",
    "    # The training configurations were not carefully selected.\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # It seems that SGD optimizer is better than Adam optimizer for ResNet18 training on ImageNet.\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1, last_epoch=-1)\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = evaluate_model(model=model, test_loader=test_loader, device=device, criterion=criterion)\n",
    "    print(\"Epoch: {:02d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(-1, eval_loss, eval_accuracy))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        eval_loss, eval_accuracy = evaluate_model(model=model, test_loader=test_loader, device=device, criterion=criterion)\n",
    "\n",
    "        # Set learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        print(\"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(epoch, train_loss, train_accuracy, eval_loss, eval_accuracy))\n",
    "\n",
    "    return model\n",
    "\n",
    "def calibrate_model(model, loader, device=torch.device(\"cuda:5\")):\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        _ = model(inputs)\n",
    "\n",
    "def measure_inference_latency(model,\n",
    "                              device,\n",
    "                              input_size=(1, 3, 32, 32),\n",
    "                              num_samples=100,\n",
    "                              num_warmups=10):\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    x = torch.rand(size=input_size).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_warmups):\n",
    "            _ = model(x)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_samples):\n",
    "            _ = model(x)\n",
    "            torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_time_ave = elapsed_time / num_samples\n",
    "\n",
    "    return elapsed_time_ave\n",
    "\n",
    "def save_model(model, model_dir, model_filename):\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "    torch.save(model.state_dict(), model_filepath)\n",
    "\n",
    "def load_model(model, model_filepath, device):\n",
    "\n",
    "    model.load_state_dict(torch.load(model_filepath, map_location=device))\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_torchscript_model(model, model_dir, model_filename):\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "    torch.jit.save(torch.jit.script(model), model_filepath)\n",
    "\n",
    "def load_torchscript_model(model_filepath, device):\n",
    "\n",
    "    model = torch.jit.load(model_filepath, map_location=device)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model(num_classes=10):\n",
    "\n",
    "    # The number of channels in ResNet18 is divisible by 8.\n",
    "    # This is required for fast GEMM integer matrix multiplication.\n",
    "    # model = torchvision.models.resnet18(pretrained=False)\n",
    "    model = resnet18(num_classes=num_classes, pretrained=False)\n",
    "\n",
    "    # We would use the pretrained ResNet18 as a feature extractor.\n",
    "    # for param in model.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    \n",
    "    # Modify the last FC layer\n",
    "    # num_features = model.fc.in_features\n",
    "    # model.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "    return model\n",
    "\n",
    "class QuantizedResNet18(nn.Module):\n",
    "    def __init__(self, model_fp32):\n",
    "        super(QuantizedResNet18, self).__init__()\n",
    "        # QuantStub converts tensors from floating point to quantized.\n",
    "        # This will only be used for inputs.\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        # DeQuantStub converts tensors from quantized to floating point.\n",
    "        # This will only be used for outputs.\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        # FP32 model\n",
    "        self.model_fp32 = model_fp32\n",
    "\n",
    "    def forward(self, x):\n",
    "        # manually specify where tensors will be converted from floating\n",
    "        # point to quantized in the quantized model\n",
    "        x = self.quant(x)\n",
    "        x = self.model_fp32(x)\n",
    "        # manually specify where tensors will be converted from quantized\n",
    "        # to floating point in the quantized model\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "def model_equivalence(model_1, model_2, device, rtol=1e-05, atol=1e-08, num_tests=100, input_size=(1,3,32,32)):\n",
    "\n",
    "    model_1.to(device)\n",
    "    model_2.to(device)\n",
    "\n",
    "    for _ in range(num_tests):\n",
    "        x = torch.rand(size=input_size).to(device)\n",
    "        y1 = model_1(x).detach().cpu().numpy()\n",
    "        y2 = model_2(x).detach().cpu().numpy()\n",
    "        if np.allclose(a=y1, b=y2, rtol=rtol, atol=atol, equal_nan=False) == False:\n",
    "            print(\"Model equivalence test sample failed: \")\n",
    "            print(y1)\n",
    "            print(y2)\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "\n",
    "    random_seed = 0\n",
    "    num_classes = 10\n",
    "    cuda_device = torch.device(\"cuda:1\")\n",
    "    cpu_device = torch.device(\"cpu:0\")\n",
    "\n",
    "    model_dir = \"saved_models\"\n",
    "    model_filename = \"resnet18_imagenet.pt\"\n",
    "    quantized_model_filename = \"resnet18_quantized_imagenet.pt\"\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "    quantized_model_filepath = os.path.join(model_dir, quantized_model_filename)\n",
    "\n",
    "    set_random_seeds(random_seed=random_seed)\n",
    "\n",
    "    # Create an untrained model.\n",
    "    model = create_model(num_classes=num_classes)\n",
    "\n",
    "    train_loader, test_loader = prepare_dataloader(num_workers=8, train_batch_size=128, eval_batch_size=256)\n",
    "    \n",
    "    # Train model.\n",
    "    print(\"Training Model...\")\n",
    "    model = train_model(model=model, train_loader=train_loader, test_loader=test_loader, device=cuda_device, learning_rate=1e-1, num_epochs=200)\n",
    "    # Save model.\n",
    "    save_model(model=model, model_dir=model_dir, model_filename=model_filename)\n",
    "    # Load a pretrained model.\n",
    "    model = load_model(model=model, model_filepath=model_filepath, device=cuda_device)\n",
    "    # Move the model to CPU since static quantization does not support CUDA currently.\n",
    "    model.to(cpu_device)\n",
    "    # Make a copy of the model for layer fusion\n",
    "    fused_model = copy.deepcopy(model)\n",
    "\n",
    "    model.train()\n",
    "    # The model has to be switched to training mode before any layer fusion.\n",
    "    # Otherwise the quantization aware training will not work correctly.\n",
    "    fused_model.train()\n",
    "    \n",
    "    # Model and fused model should be equivalent.\n",
    "    model.eval()\n",
    "    fused_model.eval()\n",
    "\n",
    "    # Fuse the model in place rather manually.\n",
    "    fused_model = torch.quantization.fuse_modules(fused_model, [[\"conv1\", \"bn1\", \"relu\"]], inplace=True)\n",
    "    for module_name, module in fused_model.named_children():\n",
    "        if \"layer\" in module_name:\n",
    "            for basic_block_name, basic_block in module.named_children():\n",
    "                torch.quantization.fuse_modules(basic_block, [[\"conv1\", \"bn1\", \"relu1\"], [\"conv2\", \"bn2\"]], inplace=True)\n",
    "                for sub_block_name, sub_block in basic_block.named_children():\n",
    "                    if sub_block_name == \"downsample\":\n",
    "                        torch.quantization.fuse_modules(sub_block, [[\"0\", \"1\"]], inplace=True)\n",
    "\n",
    "    # Print FP32 model.\n",
    "    print(model)\n",
    "    # Print fused model.\n",
    "    print(fused_model)\n",
    "\n",
    "\n",
    "    assert model_equivalence(model_1=model, model_2=fused_model, device=cpu_device, rtol=1e-03, atol=1e-06, num_tests=100, input_size=(1,3,32,32)), \"Fused model is not equivalent to the original model!\"\n",
    "\n",
    "    # Prepare the model for quantization aware training. This inserts observers in\n",
    "    # the model that will observe activation tensors during calibration.\n",
    "    quantized_model = QuantizedResNet18(model_fp32=fused_model)\n",
    "    # Using un-fused model will fail.\n",
    "    # Because there is no quantized layer implementation for a single batch normalization layer.\n",
    "    # quantized_model = QuantizedResNet18(model_fp32=model)\n",
    "    # Select quantization schemes from \n",
    "    # https://pytorch.org/docs/stable/quantization-support.html\n",
    "    quantization_config = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "    # Custom quantization configurations\n",
    "    # quantization_config = torch.quantization.default_qconfig\n",
    "    # quantization_config = torch.quantization.QConfig(activation=torch.quantization.MinMaxObserver.with_args(dtype=torch.quint8), weight=torch.quantization.MinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
    "\n",
    "    quantized_model.qconfig = quantization_config\n",
    "    \n",
    "    # Print quantization configurations\n",
    "    print(quantized_model.qconfig)\n",
    "\n",
    "    # https://pytorch.org/docs/stable/_modules/torch/quantization/quantize.html#prepare_qat\n",
    "    torch.quantization.prepare_qat(quantized_model, inplace=True)\n",
    "\n",
    "    # # Use training data for calibration.\n",
    "    print(\"Training QAT Model...\")\n",
    "    quantized_model.train()\n",
    "    train_model(model=quantized_model, train_loader=train_loader, test_loader=test_loader, device=cuda_device, learning_rate=1e-3, num_epochs=200)\n",
    "    quantized_model.to(cpu_device)\n",
    "\n",
    "    # Using high-level static quantization wrapper\n",
    "    # The above steps, including torch.quantization.prepare, calibrate_model, and torch.quantization.convert, are also equivalent to\n",
    "    # quantized_model = torch.quantization.quantize_qat(model=quantized_model, run_fn=train_model, run_args=[train_loader, test_loader, cuda_device], mapping=None, inplace=False)\n",
    "\n",
    "    quantized_model = torch.quantization.convert(quantized_model, inplace=True)\n",
    "\n",
    "    quantized_model.eval()\n",
    "\n",
    "    # Print quantized model.\n",
    "    print(quantized_model)\n",
    "\n",
    "    # Save quantized model.\n",
    "    save_torchscript_model(model=quantized_model, model_dir=model_dir, model_filename=quantized_model_filename)\n",
    "\n",
    "    # Load quantized model.\n",
    "    quantized_jit_model = load_torchscript_model(model_filepath=quantized_model_filepath, device=cpu_device)\n",
    "\n",
    "    _, fp32_eval_accuracy = evaluate_model(model=model, test_loader=test_loader, device=cpu_device, criterion=None)\n",
    "    _, int8_eval_accuracy = evaluate_model(model=quantized_jit_model, test_loader=test_loader, device=cpu_device, criterion=None)\n",
    "\n",
    "    # Skip this assertion since the values might deviate a lot.\n",
    "    # assert model_equivalence(model_1=model, model_2=quantized_jit_model, device=cpu_device, rtol=1e-01, atol=1e-02, num_tests=100, input_size=(1,3,32,32)), \"Quantized model deviates from the original model too much!\"\n",
    "\n",
    "    print(\"FP32 evaluation accuracy: {:.3f}\".format(fp32_eval_accuracy))\n",
    "    print(\"INT8 evaluation accuracy: {:.3f}\".format(int8_eval_accuracy))\n",
    "\n",
    "    fp32_cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "    int8_cpu_inference_latency = measure_inference_latency(model=quantized_model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "    int8_jit_cpu_inference_latency = measure_inference_latency(model=quantized_jit_model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "    fp32_gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "    \n",
    "    print(\"FP32 CPU Inference Latency: {:.2f} ms / sample\".format(fp32_cpu_inference_latency * 1000))\n",
    "    print(\"FP32 CUDA Inference Latency: {:.2f} ms / sample\".format(fp32_gpu_inference_latency * 1000))\n",
    "    print(\"INT8 CPU Inference Latency: {:.2f} ms / sample\".format(int8_cpu_inference_latency * 1000))\n",
    "    print(\"INT8 JIT CPU Inference Latency: {:.2f} ms / sample\".format(int8_jit_cpu_inference_latency * 1000))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118f089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
