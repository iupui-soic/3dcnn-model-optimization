{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98dc6a68",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf2a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517e13e",
   "metadata": {},
   "source": [
    "## defining own data loader and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d868ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=18.96s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.51s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Set paths and configurations\n",
    "data_dir = 'data/train2017'\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # Add any other necessary transformations\n",
    "])\n",
    "\n",
    "# Define a custom collate function\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "\n",
    "    # Resize images to a consistent size\n",
    "    max_width = max(img.shape[1] for img in images)\n",
    "    max_height = max(img.shape[2] for img in images)\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        pad_width = max_width - img.shape[1]\n",
    "        pad_height = max_height - img.shape[2]\n",
    "        padded_img = torch.nn.functional.pad(img, (0, pad_width, 0, pad_height))\n",
    "        resized_images.append(padded_img)\n",
    "\n",
    "    return resized_images, targets\n",
    "\n",
    "# Load the COCO dataset\n",
    "train_dataset = CocoDetection(root=data_dir, annFile='data/annotations/instances_train2017.json', transform=transform)\n",
    "val_dataset = CocoDetection(root=data_dir, annFile='data/annotations/instances_val2017.json', transform=transform)\n",
    "\n",
    "# Create data loaders with the custom collate function\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=collate_fn)\n",
    "\n",
    "# # Create the model\n",
    "# model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "# num_classes = len(train_dataset.coco.cats) + 1  # +1 for background class\n",
    "# model.roi_heads.box_predictor.cls_score.out_features = num_classes\n",
    "# model.roi_heads.box_predictor.bbox_pred.out_features = 4 * num_classes\n",
    "\n",
    "# # Define optimizer and loss function\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# model.to(device)\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     for images, targets in train_data_loader:\n",
    "#         images = list(image.to(device) for image in images)\n",
    "#         #targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "#         labels=[]\n",
    "#         for t in targets:\n",
    "#             for j in range(len(t)):\n",
    "#                 labels.append(t[j]['category_id'])\n",
    "\n",
    "#         loss_dict = model(images, targets)\n",
    "#         losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         losses.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     # Validation loop\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for images, targets in val_data_loader:\n",
    "#             images = list(image.to(device) for image in images)\n",
    "#             #targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "#             labels=[]\n",
    "#             for t in targets:\n",
    "#                 for j in range(len(t)):\n",
    "#                     labels.append(t[j]['category_id'])\n",
    "\n",
    "#             val_loss_dict = model(images, targets)\n",
    "#             val_losses = sum(loss for loss in val_loss_dict.values())\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}: Train Loss = {losses:.4f}, Val Loss = {val_losses:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c57e5e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11829"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8859424b",
   "metadata": {},
   "source": [
    "## Getting fewer number of images\n",
    "### It is tough to train the models directly from the train dataset, thus I am doing it for 10 batches only (total 100 images) and storing them in new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f84f935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "How many images?: 10\n",
      "2\n",
      "How many images?: 10\n",
      "3\n",
      "How many images?: 10\n",
      "4\n",
      "How many images?: 10\n",
      "5\n",
      "How many images?: 10\n",
      "6\n",
      "How many images?: 10\n",
      "7\n",
      "How many images?: 10\n",
      "8\n",
      "How many images?: 10\n",
      "9\n",
      "How many images?: 10\n",
      "10\n",
      "How many images?: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 61, 67, 1, 44, 62],\n",
       " [5, 28, 1, 28, 28, 28, 28, 1, 28, 28],\n",
       " [3, 8, 14, 14, 1, 1, 3, 14, 31, 31, 47, 47, 3],\n",
       " [9, 9, 9, 9, 9],\n",
       " [1, 23, 1],\n",
       " [82, 62, 62, 67, 51, 79, 81, 47, 51, 78, 47, 79],\n",
       " [1, 35],\n",
       " [44, 44, 67, 1, 47, 55, 49, 47, 55, 55, 55, 79, 47],\n",
       " [44,\n",
       "  32,\n",
       "  32,\n",
       "  67,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  47,\n",
       "  47,\n",
       "  47,\n",
       "  44,\n",
       "  44,\n",
       "  47,\n",
       "  47,\n",
       "  47,\n",
       "  47,\n",
       "  47,\n",
       "  47,\n",
       "  47,\n",
       "  85,\n",
       "  47,\n",
       "  1,\n",
       "  47,\n",
       "  47],\n",
       " [62,\n",
       "  62,\n",
       "  62,\n",
       "  62,\n",
       "  62,\n",
       "  62,\n",
       "  62,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  39,\n",
       "  40,\n",
       "  1,\n",
       "  37,\n",
       "  62,\n",
       "  62,\n",
       "  62,\n",
       "  1],\n",
       " [67,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  47,\n",
       "  46,\n",
       "  46,\n",
       "  46,\n",
       "  46,\n",
       "  46,\n",
       "  46,\n",
       "  46,\n",
       "  46,\n",
       "  62,\n",
       "  67,\n",
       "  1,\n",
       "  1,\n",
       "  46,\n",
       "  46,\n",
       "  46,\n",
       "  62,\n",
       "  46,\n",
       "  67,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  46],\n",
       " [70],\n",
       " [82, 78, 79],\n",
       " [16, 9],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 38, 38, 1, 1, 1, 1, 1, 1],\n",
       " [24, 24],\n",
       " [18, 19, 19, 19, 19, 1, 27, 1, 1, 27, 1, 1],\n",
       " [85, 3, 3, 1, 1, 1, 1, 1, 31, 3, 1, 31, 31, 1, 31],\n",
       " [13],\n",
       " [35, 35, 35, 35, 35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 35, 35, 1, 1, 1, 35],\n",
       " [38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 1, 38, 38],\n",
       " [47, 70, 81],\n",
       " [17, 73, 76, 74],\n",
       " [50,\n",
       "  15,\n",
       "  47,\n",
       "  48,\n",
       "  48,\n",
       "  49,\n",
       "  51,\n",
       "  57,\n",
       "  57,\n",
       "  57,\n",
       "  1,\n",
       "  57,\n",
       "  57,\n",
       "  57,\n",
       "  57,\n",
       "  57,\n",
       "  57,\n",
       "  57,\n",
       "  57,\n",
       "  62,\n",
       "  67,\n",
       "  57,\n",
       "  47,\n",
       "  57],\n",
       " [37, 1, 15, 39],\n",
       " [72, 63, 62, 67, 62],\n",
       " [62,\n",
       "  15,\n",
       "  31,\n",
       "  31,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  28,\n",
       "  28,\n",
       "  27,\n",
       "  27,\n",
       "  27,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  1,\n",
       "  28,\n",
       "  1,\n",
       "  28],\n",
       " [1, 38],\n",
       " [47, 47, 47, 81, 47, 44],\n",
       " [21, 21],\n",
       " [1, 1, 1, 1, 3, 1, 1, 1, 38, 38, 38, 1, 1, 1, 3, 1, 1, 1, 1],\n",
       " [9, 1, 1, 42, 1, 1, 1, 1, 42],\n",
       " [3],\n",
       " [63, 1, 1, 1, 73, 33, 1],\n",
       " [18, 28, 28, 62, 62, 34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [7, 7, 7],\n",
       " [38, 38, 38, 3, 3, 1, 1, 1, 1, 1, 1, 38, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1],\n",
       " [52, 55, 55, 84, 84, 84, 84],\n",
       " [8, 15],\n",
       " [86, 86, 86, 62, 67, 62],\n",
       " [17, 28],\n",
       " [28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  37,\n",
       "  62,\n",
       "  62,\n",
       "  62,\n",
       "  62,\n",
       "  62,\n",
       "  62,\n",
       "  62,\n",
       "  67,\n",
       "  67,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  43,\n",
       "  43,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  47,\n",
       "  28,\n",
       "  37,\n",
       "  47,\n",
       "  62,\n",
       "  62,\n",
       "  62,\n",
       "  62,\n",
       "  62,\n",
       "  67,\n",
       "  1,\n",
       "  62,\n",
       "  62],\n",
       " [52, 52, 52, 52, 52, 52, 52, 1, 1, 52],\n",
       " [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
       " [36, 1],\n",
       " [70, 81],\n",
       " [44, 1, 1, 1, 58, 58, 1, 31, 31, 58],\n",
       " [3, 10, 8, 8, 10],\n",
       " [24, 24, 25],\n",
       " [53, 53, 53, 53, 53],\n",
       " [6],\n",
       " [],\n",
       " [3, 1, 34, 1],\n",
       " [1, 35, 27],\n",
       " [62, 62, 86],\n",
       " [17, 73, 74, 76],\n",
       " [61],\n",
       " [13],\n",
       " [17, 63, 75],\n",
       " [3, 3, 3, 3, 1, 1, 3, 41],\n",
       " [41, 15, 1],\n",
       " [1, 1, 1, 41, 41, 41],\n",
       " [1, 41, 27, 1, 1, 3, 1, 1, 1],\n",
       " [18, 1, 31, 62],\n",
       " [54, 54, 47, 50, 47],\n",
       " [48, 61, 1, 1],\n",
       " [1, 38, 1, 1],\n",
       " [41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41],\n",
       " [1, 35],\n",
       " [67, 1, 1, 1, 47, 31, 60],\n",
       " [18, 31, 33, 15, 65, 33],\n",
       " [48, 49, 56, 56, 56, 56, 56, 56, 56, 56, 67],\n",
       " [39, 40, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [25],\n",
       " [47, 49, 50, 50, 67, 49, 47],\n",
       " [70, 81],\n",
       " [60],\n",
       " [3, 7, 1, 1, 1, 1, 3, 1, 1, 3, 1],\n",
       " [49, 50, 53, 49, 49, 81, 47, 49],\n",
       " [19, 19, 2],\n",
       " [70, 81],\n",
       " [6, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [90, 1, 1, 32, 1],\n",
       " [],\n",
       " [78, 79, 79],\n",
       " [49],\n",
       " [44, 44, 90, 48, 81, 44, 50, 51, 47, 47, 49, 51, 51, 47],\n",
       " [37, 1, 43],\n",
       " [63, 1, 75, 62],\n",
       " [65, 85],\n",
       " [19, 1, 1, 1, 1, 1, 1, 1, 13, 1, 1, 1],\n",
       " [47, 52, 52, 52],\n",
       " [38,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  16,\n",
       "  16,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  1,\n",
       "  16,\n",
       "  1],\n",
       " [63],\n",
       " [37, 1, 43, 62, 1],\n",
       " [70],\n",
       " [37, 40, 1, 40, 1],\n",
       " [1, 15, 34],\n",
       " [24, 24],\n",
       " [9, 85, 85]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels=[]\n",
    "labels=[]\n",
    "all_images=[]\n",
    "count=1\n",
    "for images, targets in train_data_loader:\n",
    "    images = list(image.to(device) for image in images)\n",
    "    all_images.extend(images)\n",
    "    print(count)\n",
    "    count=count+1\n",
    "    print(\"How many images?:\",len(images))\n",
    "    #print(images)\n",
    "#     all_labels=[]\n",
    "#     labels=[]\n",
    "    for t in targets:\n",
    "        one_image_label=[]\n",
    "        for j in range(len(t)):\n",
    "            one_image_label.append(t[j]['category_id'])\n",
    "        one_image_label_unique=list(set(one_image_label))\n",
    "        labels.append(one_image_label_unique)\n",
    "        all_labels.append(one_image_label)\n",
    "    #print(all_labels)\n",
    "    if count>10:\n",
    "        break\n",
    "    #print(labels)\n",
    "#     break\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73838ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643c5982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0624b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_images = all_images  # Your list of CUDA tensors here\n",
    "\n",
    "# Create an empty list to store the NumPy arrays\n",
    "numpy_images = []\n",
    "\n",
    "# Iterate through the CUDA tensors and convert them to NumPy arrays\n",
    "for cuda_tensor in cuda_images:\n",
    "    # Copy the tensor from GPU to CPU\n",
    "    cpu_tensor = cuda_tensor.cpu()\n",
    "\n",
    "    # Convert the CPU tensor to a NumPy array\n",
    "    numpy_array = cpu_tensor.numpy()\n",
    "\n",
    "    # Append the NumPy array to the list\n",
    "    numpy_images.append(numpy_array)\n",
    "\n",
    "def resize_images(all_images, width, height):\n",
    "    resized_images = []\n",
    "    for image in all_images:\n",
    "        image = np.transpose(image, (1, 2, 0))  # Convert from (3, height, width) to (height, width, 3)\n",
    "        pil_image = Image.fromarray((image * 255).astype('uint8'))\n",
    "        resized_image = pil_image.resize((width, height))\n",
    "        resized_image = np.array(resized_image) / 255.0\n",
    "        resized_image = np.transpose(resized_image, (2, 0, 1))  # Convert back to (3, height, width)\n",
    "        resized_images.append(resized_image)\n",
    "    return resized_images\n",
    "\n",
    "# Determine the common shape for all images\n",
    "common_width = 713\n",
    "common_height = 480\n",
    "\n",
    "# Example usage\n",
    "resized_images = resize_images(numpy_images, common_width, common_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee12730",
   "metadata": {},
   "source": [
    "## Do it for ResNet50 first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b29e222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 16:21:36.564496: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-26 16:21:38.872447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-26 16:21:38.872655: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-26 16:21:38.872666: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/tmp/ipykernel_3900554/884236791.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  all_labels = np.array(all_labels)\n",
      "2023-06-26 16:22:10.607630: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-06-26 16:22:10.607679: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-06-26 16:22:10.608837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 13s 3s/step - loss: 14.9763 - accuracy: 0.3000\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 16.4794 - accuracy: 0.5125\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 15.6017 - accuracy: 0.1750\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 10s 3s/step - loss: 16.2083 - accuracy: 0.1375\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 17.7997 - accuracy: 0.5125\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 18.7118 - accuracy: 0.5125\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 18.6614 - accuracy: 0.5125\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 19.6610 - accuracy: 0.5125\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 21.2193 - accuracy: 0.5125\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 22.7309 - accuracy: 0.5125\n",
      "1/1 [==============================] - 3s 3s/step - loss: 31.4553 - accuracy: 0.5500\n",
      "Test Loss: 31.45534324645996\n",
      "Test Accuracy: 0.550000011920929\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "Predictions: [[1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 50, 51, 52, 55, 58, 61, 62, 63, 67, 70, 75, 79, 81], [1, 3, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 7, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 75, 79, 81], [1, 3, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 7, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 37, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 7, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 7, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 37, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 7, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 37, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 37, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81], [1, 3, 7, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Step 1: Preprocess the images and labels\n",
    "# Assuming you have already resized the images and loaded them into a list\n",
    "images = resized_images  # Replace with your actual image data\n",
    "labels = all_labels  # Replace with your actual labels\n",
    "\n",
    "# Convert the images and labels to NumPy arrays\n",
    "images = np.array(images)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Reshape the images to match the input shape of ResNet50 (480, 713, 3)\n",
    "images = np.transpose(images, (0, 2, 3, 1))\n",
    "\n",
    "\n",
    "# Convert the images and labels to NumPy arrays\n",
    "images = np.array(images)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Step 2: Perform one-hot encoding of the labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_encoded = mlb.fit_transform(all_labels)\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Determine the number of classes\n",
    "num_classes = labels_encoded.shape[1]\n",
    "\n",
    "# Step 4: Build and train the model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(480, 713, 3))\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(128, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)\n",
    "\n",
    "# Step 6: Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Apply a threshold to convert probabilities to binary indicators\n",
    "threshold = 1\n",
    "binary_predictions = (predictions >= threshold).astype(int)\n",
    "\n",
    "# Convert binary indicators to labels\n",
    "decoded_predictions = []\n",
    "for pred in binary_predictions:\n",
    "    labels = [label for label, binary in zip(mlb.classes_, pred) if binary == 1]\n",
    "    decoded_predictions.append(labels)\n",
    "    \n",
    "print('Predictions:', decoded_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17c023b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[1, 44, 61, 62, 67], [1, 5, 28], [1, 3, 8, 14, 31, 47], [9], [1, 23], [47, 51, 62, 67, 78, 79, 81, 82], [1, 35], [1, 44, 47, 49, 55, 67, 79], [1, 32, 44, 47, 67, 85], [1, 37, 39, 40, 62], [1, 46, 47, 62, 67], [70], [78, 79, 82], [9, 16], [1, 38], [24], [1, 18, 19, 27], [1, 3, 31, 85], [13], [1, 35], [1, 38], [47, 70, 81], [17, 73, 74, 76], [1, 15, 47, 48, 49, 50, 51, 57, 62, 67], [1, 15, 37, 39], [62, 63, 67, 72], [1, 15, 27, 28, 31, 62], [1, 38], [44, 47, 81], [21], [1, 3, 38], [1, 9, 42], [3], [1, 33, 63, 73], [1, 18, 28, 34, 62], [7], [1, 3, 38], [52, 55, 84], [8, 15], [62, 67, 86], [17, 28], [1, 28, 37, 43, 47, 62, 67], [1, 52], [20], [1, 36], [70, 81], [1, 31, 44, 58], [3, 8, 10], [24, 25], [53], [6], [], [1, 3, 34], [1, 27, 35], [62, 86], [17, 73, 74, 76], [61], [13], [17, 63, 75], [1, 3, 41], [1, 15, 41], [1, 41], [1, 3, 27, 41], [1, 18, 31, 62], [47, 50, 54], [1, 48, 61], [1, 38], [1, 41], [1, 35], [1, 31, 47, 60, 67], [15, 18, 31, 33, 65], [48, 49, 56, 67], [1, 39, 40], [25], [47, 49, 50, 67], [70, 81], [60], [1, 3, 7], [47, 49, 50, 53, 81], [2, 19], [70, 81], [1, 6], [1, 32, 90], [], [78, 79], [49], [44, 47, 48, 49, 50, 51, 81, 90], [1, 37, 43], [1, 62, 63, 75], [65, 85], [1, 13, 19], [47, 52], [1, 16, 31, 38], [63], [1, 37, 43, 62], [70], [1, 37, 40], [1, 15, 34], [24], [9, 85]]\n"
     ]
    }
   ],
   "source": [
    "decoded_originals = []\n",
    "for pred in labels_encoded:\n",
    "    labels = [label for label, binary in zip(mlb.classes_, pred) if binary == 1]\n",
    "    decoded_originals.append(labels)\n",
    "    \n",
    "print('Predictions:', decoded_originals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e886d83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 50, 51, 52, 55, 58, 61, 62, 63, 67, 70, 75, 79, 81] \n",
      "\n",
      "[1, 3, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 7, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 75, 79, 81] \n",
      "\n",
      "[1, 3, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 7, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 37, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 7, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 7, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 37, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 7, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 37, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 37, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 9, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n",
      "[1, 3, 7, 9, 15, 16, 18, 19, 24, 27, 28, 31, 32, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 55, 58, 61, 62, 63, 67, 70, 72, 75, 79, 81] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(decoded_predictions)):\n",
    "    print(decoded_predictions[i],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229af000",
   "metadata": {},
   "source": [
    "## The result is very bad because we have too many labels and very less images compared to that. We need to do the training with all the images\n",
    "Find an efficient way to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81185a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2d99536",
   "metadata": {},
   "source": [
    "## Trying it on rough model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3ad0282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 3s 635ms/step - loss: 1238.4291 - accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 2s 719ms/step - loss: 1909.1940 - accuracy: 0.0375\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 2s 511ms/step - loss: 2054.2251 - accuracy: 0.4500\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 2s 520ms/step - loss: 2347.0261 - accuracy: 0.3625\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 2s 491ms/step - loss: 2525.9229 - accuracy: 0.2500\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 479ms/step - loss: 2811.5308 - accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 469ms/step - loss: 3178.6997 - accuracy: 0.3000\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 479ms/step - loss: 3598.5945 - accuracy: 0.2750\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 458ms/step - loss: 3979.5281 - accuracy: 0.3000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 498ms/step - loss: 4366.3711 - accuracy: 0.3500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 7375.4297 - accuracy: 0.3000\n",
      "Test Loss: 7375.4296875\n",
      "Test Accuracy: 0.30000001192092896\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Predictions: [[47, 67], [1, 41, 49], [1, 47], [1, 38, 49], [1, 49], [3], [47], [1, 3], [1, 41, 49], [1, 49], [3], [1, 67], [1, 3], [1, 3, 9, 18, 41, 47], [1, 3], [1], [49], [1], [1, 49], [1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Preprocess the images and labels\n",
    "# Assuming you have already resized the images and loaded them into a list\n",
    "images = resized_images  # Replace with your actual image data\n",
    "labels = all_labels  # Replace with your actual labels\n",
    "\n",
    "# Convert the images and labels to NumPy arrays\n",
    "images = np.array(images)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "\n",
    "# Step 2: Perform one-hot encoding of the labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_encoded = mlb.fit_transform(all_labels)\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Determine the number of classes\n",
    "num_classes = labels_encoded.shape[1]\n",
    "\n",
    "# Step 4: Build and train the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(3, 480, 713)),  # Flatten the input\n",
    "    keras.layers.Dense(128, activation='relu'),  # Add a hidden dense layer\n",
    "    keras.layers.Dense(num_classes, activation='softmax')  # Output layer with softmax activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)\n",
    "\n",
    "# Step 6: Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Apply a threshold to convert probabilities to binary indicators\n",
    "threshold = 0\n",
    "binary_predictions = (predictions > threshold).astype(int)\n",
    "\n",
    "# Convert binary indicators to labels\n",
    "decoded_predictions = []\n",
    "for pred in binary_predictions:\n",
    "    labels = [label for label, binary in zip(mlb.classes_, pred) if binary == 1]\n",
    "    decoded_predictions.append(labels)\n",
    "    \n",
    "#decoded_predictions = mlb.inverse_transform(predictions)\n",
    "print('Predictions:', decoded_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "455a7219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(),\n",
       " (1, 27, 35),\n",
       " (15, 18, 31, 33, 65),\n",
       " (70, 81),\n",
       " (1, 36),\n",
       " (62, 67, 86),\n",
       " (17, 73, 74, 76),\n",
       " (70, 81),\n",
       " (1, 46, 47, 62, 67),\n",
       " (1, 44, 61, 62, 67),\n",
       " (13,),\n",
       " (1, 3, 38),\n",
       " (25,),\n",
       " (1, 33, 63, 73),\n",
       " (1, 13, 19),\n",
       " (1, 23),\n",
       " (60,),\n",
       " (1, 3, 7),\n",
       " (78, 79, 82),\n",
       " (1, 9, 42)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_originals = mlb.inverse_transform(y_test)\n",
    "decoded_originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "380641a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[47, 67],\n",
       " [1, 41, 49],\n",
       " [1, 47],\n",
       " [1, 38, 49],\n",
       " [1, 49],\n",
       " [3],\n",
       " [47],\n",
       " [1, 3],\n",
       " [1, 41, 49],\n",
       " [1, 49],\n",
       " [3],\n",
       " [1, 67],\n",
       " [1, 3],\n",
       " [1, 3, 9, 18, 41, 47],\n",
       " [1, 3],\n",
       " [1],\n",
       " [49],\n",
       " [1],\n",
       " [1, 49],\n",
       " [1]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2af1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
